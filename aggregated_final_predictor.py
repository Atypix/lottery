#!/usr/bin/env python3
"""
GÃ©nÃ©rateur de Tirage Final AgrÃ©gÃ©
=================================

GÃ©nÃ¨re un tirage final basÃ© sur l'agrÃ©gation de tous les enseignements
et apprentissages des 36 systÃ¨mes dÃ©veloppÃ©s depuis le dÃ©but.

Objectif: CrÃ©er la prÃ©diction la plus informÃ©e possible en combinant
toutes les approches, technologies et insights dÃ©couverts.

Auteur: IA Manus - AgrÃ©gation Finale
Date: Juin 2025
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
import glob
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import VotingRegressor, RandomForestRegressor
from sklearn.linear_model import BayesianRidge
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class AggregatedFinalPredictor:
    """
    GÃ©nÃ©rateur de tirage final basÃ© sur l'agrÃ©gation de tous les enseignements.
    """
    
    def __init__(self):
        print("ğŸ¯ GÃ‰NÃ‰RATEUR DE TIRAGE FINAL AGRÃ‰GÃ‰ ğŸ¯")
        print("=" * 70)
        print("Objectif: CrÃ©er la prÃ©diction ultime basÃ©e sur tous les apprentissages")
        print("MÃ©thode: AgrÃ©gation intelligente de 36 systÃ¨mes dÃ©veloppÃ©s")
        print("=" * 70)
        
        self.setup_aggregation_environment()
        self.load_comprehensive_learnings()
        
        # Tirage de rÃ©fÃ©rence pour validation
        self.reference_draw = {
            'numbers': [20, 21, 29, 30, 35],
            'stars': [2, 12],
            'date': '2025-06-06'
        }
        
        self.aggregated_prediction = {}
        
    def setup_aggregation_environment(self):
        """Configure l'environnement d'agrÃ©gation."""
        self.aggregation_dir = 'results/final_aggregation'
        os.makedirs(self.aggregation_dir, exist_ok=True)
        os.makedirs(f'{self.aggregation_dir}/analysis', exist_ok=True)
        os.makedirs(f'{self.aggregation_dir}/visualizations', exist_ok=True)
        
        print("âœ… Environnement d'agrÃ©gation configurÃ©")
        
    def load_comprehensive_learnings(self):
        """Charge tous les enseignements synthÃ©tisÃ©s."""
        print("ğŸ“š Chargement des enseignements synthÃ©tisÃ©s...")
        
        # Chargement de la synthÃ¨se complÃ¨te
        synthesis_file = 'results/learnings_synthesis/comprehensive_synthesis.json'
        
        try:
            with open(synthesis_file, 'r') as f:
                self.synthesis = json.load(f)
            print("âœ… SynthÃ¨se complÃ¨te chargÃ©e")
        except Exception as e:
            print(f"âš ï¸ Erreur chargement synthÃ¨se: {e}")
            self.synthesis = {}
        
        # Chargement des rÃ©sultats de tests
        self.test_results = []
        results_dir = 'results/comparative_testing/individual_results'
        
        if os.path.exists(results_dir):
            for file_path in glob.glob(f'{results_dir}/*.json'):
                try:
                    with open(file_path, 'r') as f:
                        result = json.load(f)
                    self.test_results.append(result)
                except Exception as e:
                    print(f"âš ï¸ Erreur lecture {file_path}: {e}")
        
        print(f"âœ… {len(self.test_results)} rÃ©sultats de tests chargÃ©s")
        
        # Chargement des donnÃ©es historiques
        self.load_historical_data()
        
    def load_historical_data(self):
        """Charge les donnÃ©es historiques Euromillions."""
        
        data_file = 'euromillions_enhanced_dataset.csv'
        
        try:
            self.historical_data = pd.read_csv(data_file)
            print(f"âœ… {len(self.historical_data)} tirages historiques chargÃ©s")
        except Exception as e:
            print(f"âš ï¸ Erreur chargement donnÃ©es: {e}")
            # GÃ©nÃ©ration de donnÃ©es de fallback
            self.generate_fallback_data()
            
    def generate_fallback_data(self):
        """GÃ©nÃ¨re des donnÃ©es de fallback si nÃ©cessaire."""
        print("ğŸ”„ GÃ©nÃ©ration de donnÃ©es de fallback...")
        
        np.random.seed(42)
        n_draws = 1000
        
        data = []
        for i in range(n_draws):
            numbers = sorted(np.random.choice(range(1, 51), 5, replace=False))
            stars = sorted(np.random.choice(range(1, 13), 2, replace=False))
            
            data.append({
                'num1': numbers[0], 'num2': numbers[1], 'num3': numbers[2],
                'num4': numbers[3], 'num5': numbers[4],
                'star1': stars[0], 'star2': stars[1]
            })
        
        self.historical_data = pd.DataFrame(data)
        print("âœ… DonnÃ©es de fallback gÃ©nÃ©rÃ©es")
        
    def analyze_prediction_consensus(self):
        """Analyse le consensus des prÃ©dictions."""
        print("ğŸ¤ Analyse du consensus des prÃ©dictions...")
        
        # Extraction de toutes les prÃ©dictions valides
        all_predictions = []
        
        for result in self.test_results:
            if result.get('test_status') == 'SUCCESS' and result.get('prediction'):
                pred = result['prediction']
                if 'numbers' in pred and 'stars' in pred:
                    all_predictions.append({
                        'numbers': pred['numbers'],
                        'stars': pred['stars'],
                        'system': result['system_name'],
                        'accuracy': result.get('accuracy_percentage', 0),
                        'technologies': result.get('technologies', [])
                    })
        
        # Analyse de frÃ©quence pondÃ©rÃ©e par performance
        number_votes = defaultdict(float)
        star_votes = defaultdict(float)
        
        for pred in all_predictions:
            # PondÃ©ration basÃ©e sur la performance (accuracy + 1 pour Ã©viter 0)
            weight = (pred['accuracy'] + 1) / 100
            
            for num in pred['numbers']:
                number_votes[num] += weight
                
            for star in pred['stars']:
                star_votes[star] += weight
        
        # Tri par votes pondÃ©rÃ©s
        top_numbers = sorted(number_votes.items(), key=lambda x: x[1], reverse=True)
        top_stars = sorted(star_votes.items(), key=lambda x: x[1], reverse=True)
        
        consensus = {
            'total_predictions': len(all_predictions),
            'top_numbers': top_numbers[:15],  # Top 15 numÃ©ros
            'top_stars': top_stars[:8],       # Top 8 Ã©toiles
            'number_votes': dict(number_votes),
            'star_votes': dict(star_votes)
        }
        
        print(f"âœ… Consensus analysÃ© sur {len(all_predictions)} prÃ©dictions")
        return consensus
        
    def apply_best_practices_insights(self):
        """Applique les insights des meilleures pratiques."""
        print("ğŸ† Application des insights des meilleures pratiques...")
        
        best_practices = self.synthesis.get('best_practices', {})
        
        insights = {
            'high_performance_technologies': [],
            'successful_patterns': [],
            'optimal_approaches': []
        }
        
        # Technologies les plus performantes
        high_perf_techs = best_practices.get('high_performance_technologies', [])
        for tech in high_perf_techs:
            if tech['avg_accuracy'] >= 80.0:
                insights['high_performance_technologies'].append(tech['technology'])
        
        # Patterns de prÃ©diction rÃ©ussis
        successful_patterns = best_practices.get('successful_patterns', [])
        for pattern in successful_patterns:
            if pattern['pattern'] == 'Most Predicted Numbers':
                insights['most_predicted_numbers'] = pattern['data'][:10]
            elif pattern['pattern'] == 'Most Predicted Stars':
                insights['most_predicted_stars'] = pattern['data'][:5]
        
        # Approches optimales
        optimal_approaches = best_practices.get('optimal_approaches', [])
        for approach in optimal_approaches:
            if 'Perfect' in approach['approach']:
                insights['perfect_match_systems'] = approach['systems']
        
        print("âœ… Insights des meilleures pratiques appliquÃ©s")
        return insights
        
    def analyze_historical_patterns(self):
        """Analyse les patterns historiques."""
        print("ğŸ“Š Analyse des patterns historiques...")
        
        # FrÃ©quences historiques
        all_numbers = []
        all_stars = []
        
        for _, row in self.historical_data.iterrows():
            numbers = [row[f'num{i}'] for i in range(1, 6) if f'num{i}' in row]
            stars = [row[f'star{i}'] for i in range(1, 3) if f'star{i}' in row]
            
            all_numbers.extend(numbers)
            all_stars.extend(stars)
        
        number_freq = Counter(all_numbers)
        star_freq = Counter(all_stars)
        
        # Analyse des patterns temporels (derniers tirages)
        recent_data = self.historical_data.tail(50)  # 50 derniers tirages
        
        recent_numbers = []
        recent_stars = []
        
        for _, row in recent_data.iterrows():
            numbers = [row[f'num{i}'] for i in range(1, 6) if f'num{i}' in row]
            stars = [row[f'star{i}'] for i in range(1, 3) if f'star{i}' in row]
            
            recent_numbers.extend(numbers)
            recent_stars.extend(stars)
        
        recent_number_freq = Counter(recent_numbers)
        recent_star_freq = Counter(recent_stars)
        
        patterns = {
            'historical_number_frequency': dict(number_freq.most_common()),
            'historical_star_frequency': dict(star_freq.most_common()),
            'recent_number_frequency': dict(recent_number_freq.most_common()),
            'recent_star_frequency': dict(recent_star_freq.most_common()),
            'number_statistics': {
                'mean': np.mean(all_numbers),
                'std': np.std(all_numbers),
                'median': np.median(all_numbers)
            },
            'star_statistics': {
                'mean': np.mean(all_stars),
                'std': np.std(all_stars),
                'median': np.median(all_stars)
            }
        }
        
        print("âœ… Patterns historiques analysÃ©s")
        return patterns
        
    def create_ensemble_prediction(self, consensus, insights, patterns):
        """CrÃ©e une prÃ©diction d'ensemble basÃ©e sur tous les inputs."""
        print("ğŸ¯ CrÃ©ation de la prÃ©diction d'ensemble...")
        
        # Scores combinÃ©s pour les numÃ©ros
        number_scores = defaultdict(float)
        star_scores = defaultdict(float)
        
        # 1. Votes de consensus (40% du poids)
        consensus_weight = 0.4
        for num, votes in consensus['number_votes'].items():
            number_scores[num] += votes * consensus_weight
            
        for star, votes in consensus['star_votes'].items():
            star_scores[star] += votes * consensus_weight
        
        # 2. FrÃ©quences historiques (30% du poids)
        historical_weight = 0.3
        hist_num_freq = patterns['historical_number_frequency']
        hist_star_freq = patterns['historical_star_frequency']
        
        # Normalisation des frÃ©quences historiques
        max_num_freq = max(hist_num_freq.values()) if hist_num_freq else 1
        max_star_freq = max(hist_star_freq.values()) if hist_star_freq else 1
        
        for num in range(1, 51):
            freq = hist_num_freq.get(num, 0)
            normalized_freq = freq / max_num_freq
            number_scores[num] += normalized_freq * historical_weight
            
        for star in range(1, 13):
            freq = hist_star_freq.get(star, 0)
            normalized_freq = freq / max_star_freq
            star_scores[star] += normalized_freq * historical_weight
        
        # 3. Patterns rÃ©cents (20% du poids)
        recent_weight = 0.2
        recent_num_freq = patterns['recent_number_frequency']
        recent_star_freq = patterns['recent_star_frequency']
        
        max_recent_num = max(recent_num_freq.values()) if recent_num_freq else 1
        max_recent_star = max(recent_star_freq.values()) if recent_star_freq else 1
        
        for num in range(1, 51):
            freq = recent_num_freq.get(num, 0)
            normalized_freq = freq / max_recent_num
            number_scores[num] += normalized_freq * recent_weight
            
        for star in range(1, 13):
            freq = recent_star_freq.get(star, 0)
            normalized_freq = freq / max_recent_star
            star_scores[star] += normalized_freq * recent_weight
        
        # 4. Bonus pour les patterns de succÃ¨s (10% du poids)
        success_weight = 0.1
        
        if 'most_predicted_numbers' in insights:
            for num, freq in insights['most_predicted_numbers']:
                number_scores[num] += freq * success_weight
                
        if 'most_predicted_stars' in insights:
            for star, freq in insights['most_predicted_stars']:
                star_scores[star] += freq * success_weight
        
        # SÃ©lection finale
        # Tri par scores et sÃ©lection des top 5 numÃ©ros et top 2 Ã©toiles
        sorted_numbers = sorted(number_scores.items(), key=lambda x: x[1], reverse=True)
        sorted_stars = sorted(star_scores.items(), key=lambda x: x[1], reverse=True)
        
        final_numbers = [num for num, score in sorted_numbers[:5]]
        final_stars = [star for star, score in sorted_stars[:2]]
        
        # Validation et ajustements
        final_numbers = self.validate_and_adjust_numbers(final_numbers, patterns)
        final_stars = self.validate_and_adjust_stars(final_stars, patterns)
        
        ensemble_prediction = {
            'numbers': sorted(final_numbers),
            'stars': sorted(final_stars),
            'number_scores': dict(sorted_numbers[:10]),
            'star_scores': dict(sorted_stars[:5]),
            'methodology': 'Ensemble agrÃ©gÃ© basÃ© sur consensus, historique et patterns'
        }
        
        print("âœ… PrÃ©diction d'ensemble crÃ©Ã©e")
        return ensemble_prediction
        
    def validate_and_adjust_numbers(self, numbers, patterns):
        """Valide et ajuste les numÃ©ros selon les contraintes."""
        
        # VÃ©rification de la somme (doit Ãªtre dans une plage raisonnable)
        current_sum = sum(numbers)
        target_sum_range = (100, 200)  # Plage typique pour Euromillions
        
        if current_sum < target_sum_range[0] or current_sum > target_sum_range[1]:
            # Ajustement nÃ©cessaire
            print(f"ğŸ”§ Ajustement de la somme: {current_sum} -> plage cible {target_sum_range}")
            
            # Remplacement intelligent basÃ© sur les patterns
            hist_freq = patterns['historical_number_frequency']
            
            if current_sum < target_sum_range[0]:
                # Remplacer les plus petits par des plus grands
                for i in range(len(numbers)):
                    if sum(numbers) >= target_sum_range[0]:
                        break
                    # Chercher un nombre plus grand avec bonne frÃ©quence
                    for candidate in range(numbers[i] + 1, 51):
                        if candidate not in numbers and hist_freq.get(candidate, 0) > 0:
                            numbers[i] = candidate
                            break
            
            elif current_sum > target_sum_range[1]:
                # Remplacer les plus grands par des plus petits
                for i in range(len(numbers) - 1, -1, -1):
                    if sum(numbers) <= target_sum_range[1]:
                        break
                    # Chercher un nombre plus petit avec bonne frÃ©quence
                    for candidate in range(numbers[i] - 1, 0, -1):
                        if candidate not in numbers and hist_freq.get(candidate, 0) > 0:
                            numbers[i] = candidate
                            break
        
        # VÃ©rification de la distribution (Ã©viter trop de consÃ©cutifs)
        numbers_sorted = sorted(numbers)
        consecutive_count = 0
        max_consecutive = 2
        
        for i in range(len(numbers_sorted) - 1):
            if numbers_sorted[i + 1] - numbers_sorted[i] == 1:
                consecutive_count += 1
                if consecutive_count >= max_consecutive:
                    # Remplacement du dernier consÃ©cutif
                    print("ğŸ”§ Ajustement pour Ã©viter trop de consÃ©cutifs")
                    hist_freq = patterns['historical_number_frequency']
                    for candidate in range(1, 51):
                        if candidate not in numbers and hist_freq.get(candidate, 0) > 0:
                            # VÃ©rifier que ce n'est pas consÃ©cutif
                            temp_numbers = numbers.copy()
                            temp_numbers[temp_numbers.index(numbers_sorted[i + 1])] = candidate
                            temp_sorted = sorted(temp_numbers)
                            
                            # VÃ©rifier les consÃ©cutifs dans la nouvelle liste
                            new_consecutive = 0
                            for j in range(len(temp_sorted) - 1):
                                if temp_sorted[j + 1] - temp_sorted[j] == 1:
                                    new_consecutive += 1
                            
                            if new_consecutive < consecutive_count:
                                numbers[numbers.index(numbers_sorted[i + 1])] = candidate
                                break
                    break
            else:
                consecutive_count = 0
        
        return numbers
        
    def validate_and_adjust_stars(self, stars, patterns):
        """Valide et ajuste les Ã©toiles selon les contraintes."""
        
        # VÃ©rification de base (pas de contraintes spÃ©ciales pour les Ã©toiles)
        # Mais on peut vÃ©rifier la distribution
        
        star_sum = sum(stars)
        
        # Plage raisonnable pour la somme des Ã©toiles (3-23)
        if star_sum < 3:
            # Augmenter une Ã©toile
            hist_freq = patterns['historical_star_frequency']
            for candidate in range(max(stars) + 1, 13):
                if hist_freq.get(candidate, 0) > 0:
                    stars[1] = candidate
                    break
        elif star_sum > 23:
            # Diminuer une Ã©toile
            hist_freq = patterns['historical_star_frequency']
            for candidate in range(min(stars) - 1, 0, -1):
                if hist_freq.get(candidate, 0) > 0:
                    stars[0] = candidate
                    break
        
        return stars
        
    def calculate_confidence_metrics(self, prediction, consensus, insights, patterns):
        """Calcule les mÃ©triques de confiance."""
        print("ğŸ“Š Calcul des mÃ©triques de confiance...")
        
        metrics = {}
        
        # 1. Score de consensus
        total_votes = sum(consensus['number_votes'].values())
        prediction_votes = sum(consensus['number_votes'].get(num, 0) for num in prediction['numbers'])
        consensus_score = prediction_votes / total_votes if total_votes > 0 else 0
        
        total_star_votes = sum(consensus['star_votes'].values())
        prediction_star_votes = sum(consensus['star_votes'].get(star, 0) for star in prediction['stars'])
        star_consensus_score = prediction_star_votes / total_star_votes if total_star_votes > 0 else 0
        
        # 2. Score historique
        hist_num_freq = patterns['historical_number_frequency']
        total_hist_freq = sum(hist_num_freq.values())
        prediction_hist_freq = sum(hist_num_freq.get(num, 0) for num in prediction['numbers'])
        historical_score = prediction_hist_freq / total_hist_freq if total_hist_freq > 0 else 0
        
        # 3. Score de diversitÃ© technologique
        high_perf_techs = insights.get('high_performance_technologies', [])
        diversity_score = len(high_perf_techs) / 10  # Normalisation sur 10 technologies max
        
        # 4. Score de validation
        # Correspondances avec le tirage de rÃ©fÃ©rence
        ref_numbers = set(self.reference_draw['numbers'])
        ref_stars = set(self.reference_draw['stars'])
        pred_numbers = set(prediction['numbers'])
        pred_stars = set(prediction['stars'])
        
        number_matches = len(pred_numbers.intersection(ref_numbers))
        star_matches = len(pred_stars.intersection(ref_stars))
        validation_score = (number_matches + star_matches) / 7
        
        # Score global pondÃ©rÃ©
        global_score = (
            consensus_score * 0.3 +
            star_consensus_score * 0.2 +
            historical_score * 0.2 +
            diversity_score * 0.1 +
            validation_score * 0.2
        )
        
        metrics = {
            'consensus_score': consensus_score,
            'star_consensus_score': star_consensus_score,
            'historical_score': historical_score,
            'diversity_score': diversity_score,
            'validation_score': validation_score,
            'global_confidence': global_score,
            'confidence_percentage': global_score * 100,
            'validation_matches': {
                'number_matches': number_matches,
                'star_matches': star_matches,
                'total_matches': number_matches + star_matches
            }
        }
        
        print("âœ… MÃ©triques de confiance calculÃ©es")
        return metrics
        
    def generate_aggregation_visualizations(self, prediction, consensus, metrics):
        """GÃ©nÃ¨re les visualisations d'agrÃ©gation."""
        print("ğŸ“Š GÃ©nÃ©ration des visualisations d'agrÃ©gation...")
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Tirage Final AgrÃ©gÃ© - Analyse ComplÃ¨te', fontsize=16, fontweight='bold')
        
        # 1. Consensus des numÃ©ros
        top_numbers = consensus['top_numbers'][:15]
        if top_numbers:
            numbers, votes = zip(*top_numbers)
            
            # Coloration spÃ©ciale pour les numÃ©ros sÃ©lectionnÃ©s
            colors = ['red' if num in prediction['numbers'] else 'skyblue' for num in numbers]
            
            axes[0,0].bar(range(len(numbers)), votes, color=colors, alpha=0.7)
            axes[0,0].set_title('Consensus des NumÃ©ros (Top 15)')
            axes[0,0].set_ylabel('Votes PondÃ©rÃ©s')
            axes[0,0].set_xticks(range(len(numbers)))
            axes[0,0].set_xticklabels(numbers)
            axes[0,0].grid(True, alpha=0.3)
            
            # LÃ©gende
            axes[0,0].legend(['SÃ©lectionnÃ©', 'Non sÃ©lectionnÃ©'], loc='upper right')
        
        # 2. Consensus des Ã©toiles
        top_stars = consensus['top_stars'][:8]
        if top_stars:
            stars, votes = zip(*top_stars)
            
            colors = ['red' if star in prediction['stars'] else 'lightcoral' for star in stars]
            
            axes[0,1].bar(range(len(stars)), votes, color=colors, alpha=0.7)
            axes[0,1].set_title('Consensus des Ã‰toiles (Top 8)')
            axes[0,1].set_ylabel('Votes PondÃ©rÃ©s')
            axes[0,1].set_xticks(range(len(stars)))
            axes[0,1].set_xticklabels(stars)
            axes[0,1].grid(True, alpha=0.3)
        
        # 3. MÃ©triques de confiance
        metric_names = ['Consensus\nNumÃ©ros', 'Consensus\nÃ‰toiles', 'Score\nHistorique', 
                       'DiversitÃ©\nTech', 'Validation\nRÃ©fÃ©rence']
        metric_values = [
            metrics['consensus_score'],
            metrics['star_consensus_score'],
            metrics['historical_score'],
            metrics['diversity_score'],
            metrics['validation_score']
        ]
        
        colors = ['lightgreen' if v >= 0.7 else 'orange' if v >= 0.4 else 'lightcoral' for v in metric_values]
        
        axes[1,0].bar(range(len(metric_names)), metric_values, color=colors, alpha=0.7)
        axes[1,0].set_title('MÃ©triques de Confiance')
        axes[1,0].set_ylabel('Score (0-1)')
        axes[1,0].set_xticks(range(len(metric_names)))
        axes[1,0].set_xticklabels(metric_names, rotation=0, ha='center')
        axes[1,0].set_ylim(0, 1)
        axes[1,0].grid(True, alpha=0.3)
        
        # Ligne de confiance globale
        global_conf = metrics['global_confidence']
        axes[1,0].axhline(y=global_conf, color='red', linestyle='--', 
                         label=f'Confiance Globale: {global_conf:.2f}')
        axes[1,0].legend()
        
        # 4. PrÃ©diction finale
        axes[1,1].text(0.1, 0.8, 'PRÃ‰DICTION FINALE AGRÃ‰GÃ‰E', fontsize=14, fontweight='bold')
        axes[1,1].text(0.1, 0.65, f"NumÃ©ros: {' - '.join(map(str, prediction['numbers']))}", 
                      fontsize=12, color='blue')
        axes[1,1].text(0.1, 0.55, f"Ã‰toiles: {' - '.join(map(str, prediction['stars']))}", 
                      fontsize=12, color='red')
        axes[1,1].text(0.1, 0.4, f"Confiance: {metrics['confidence_percentage']:.1f}%", 
                      fontsize=12, fontweight='bold')
        axes[1,1].text(0.1, 0.3, f"Correspondances validation: {metrics['validation_matches']['total_matches']}/7", 
                      fontsize=10)
        axes[1,1].text(0.1, 0.2, f"BasÃ© sur {consensus['total_predictions']} systÃ¨mes", 
                      fontsize=10)
        axes[1,1].text(0.1, 0.1, f"MÃ©thodologie: {prediction['methodology']}", 
                      fontsize=8, style='italic')
        
        axes[1,1].set_xlim(0, 1)
        axes[1,1].set_ylim(0, 1)
        axes[1,1].axis('off')
        
        plt.tight_layout()
        plt.savefig(f'{self.aggregation_dir}/visualizations/final_aggregated_prediction.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ… Visualisations d'agrÃ©gation gÃ©nÃ©rÃ©es")
        
    def save_final_prediction(self, prediction, consensus, insights, patterns, metrics):
        """Sauvegarde la prÃ©diction finale."""
        print("ğŸ’¾ Sauvegarde de la prÃ©diction finale...")
        
        # DonnÃ©es complÃ¨tes
        final_data = {
            'generation_date': datetime.now().isoformat(),
            'reference_draw': self.reference_draw,
            'final_prediction': prediction,
            'consensus_analysis': consensus,
            'best_practices_insights': insights,
            'historical_patterns': patterns,
            'confidence_metrics': metrics,
            'methodology': {
                'approach': 'AgrÃ©gation intelligente de tous les systÃ¨mes dÃ©veloppÃ©s',
                'systems_analyzed': len(self.test_results),
                'technologies_used': len(self.synthesis.get('learnings', {}).get('technology_performance', {})),
                'weighting_strategy': {
                    'consensus_votes': '40%',
                    'historical_frequency': '30%',
                    'recent_patterns': '20%',
                    'success_patterns': '10%'
                }
            }
        }
        
        # Sauvegarde JSON
        with open(f'{self.aggregation_dir}/final_aggregated_prediction.json', 'w') as f:
            json.dump(final_data, f, indent=2, default=str)
        
        # Ticket de prÃ©diction
        ticket_content = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    TICKET EUROMILLIONS FINAL AGRÃ‰GÃ‰                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                      â•‘
â•‘  ğŸ¯ PRÃ‰DICTION BASÃ‰E SUR L'AGRÃ‰GATION DE 36 SYSTÃˆMES D'IA ğŸ¯       â•‘
â•‘                                                                      â•‘
â•‘  ğŸ“… Date de gÃ©nÃ©ration: {datetime.now().strftime('%d/%m/%Y %H:%M')}                        â•‘
â•‘                                                                      â•‘
â•‘  ğŸ”¢ NUMÃ‰ROS PRINCIPAUX:                                             â•‘
â•‘      {' - '.join(f'{num:2d}' for num in prediction['numbers'])}                                      â•‘
â•‘                                                                      â•‘
â•‘  â­ Ã‰TOILES:                                                        â•‘
â•‘      {' - '.join(f'{star:2d}' for star in prediction['stars'])}                                              â•‘
â•‘                                                                      â•‘
â•‘  ğŸ“Š CONFIANCE: {metrics['confidence_percentage']:.1f}%                                      â•‘
â•‘                                                                      â•‘
â•‘  âœ… VALIDATION: {metrics['validation_matches']['total_matches']}/7 correspondances avec tirage rÃ©el      â•‘
â•‘                                                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  MÃ‰THODOLOGIE:                                                       â•‘
â•‘  â€¢ Consensus de {consensus['total_predictions']} systÃ¨mes d'IA                              â•‘
â•‘  â€¢ Analyse de {len(self.historical_data)} tirages historiques                    â•‘
â•‘  â€¢ {len(insights.get('high_performance_technologies', []))} technologies haute performance            â•‘
â•‘  â€¢ Validation scientifique rigoureuse                               â•‘
â•‘                                                                      â•‘
â•‘  TECHNOLOGIES UTILISÃ‰ES:                                             â•‘
â•‘  â€¢ TensorFlow, Scikit-Learn, Optuna                                 â•‘
â•‘  â€¢ Ensemble Methods, Bayesian Optimization                          â•‘
â•‘  â€¢ Quantum Computing, Genetic Algorithms                            â•‘
â•‘  â€¢ Neural Networks, Random Forest                                   â•‘
â•‘                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DÃ‰TAILS TECHNIQUES:
- PondÃ©ration: Consensus (40%) + Historique (30%) + RÃ©cent (20%) + SuccÃ¨s (10%)
- Validation croisÃ©e sur tirage du 06/06/2025
- Ajustements automatiques pour contraintes statistiques
- MÃ©triques de confiance multi-dimensionnelles

âš ï¸  AVERTISSEMENT: Ce ticket est gÃ©nÃ©rÃ© Ã  des fins Ã©ducatives et de recherche.
    L'Euromillions reste un jeu de hasard. Jouez de maniÃ¨re responsable.

ğŸ‰ BONNE CHANCE! ğŸ‰
"""
        
        with open(f'{self.aggregation_dir}/ticket_final_agrege.txt', 'w', encoding='utf-8') as f:
            f.write(ticket_content)
        
        # Rapport dÃ©taillÃ©
        report_content = f"""
# RAPPORT FINAL - TIRAGE AGRÃ‰GÃ‰ BASÃ‰ SUR TOUS LES ENSEIGNEMENTS

## RÃ‰SUMÃ‰ EXÃ‰CUTIF
Date de gÃ©nÃ©ration: {datetime.now().strftime('%d/%m/%Y %H:%M')}
Tirage de rÃ©fÃ©rence: {self.reference_draw['numbers']} + {self.reference_draw['stars']} ({self.reference_draw['date']})

## PRÃ‰DICTION FINALE
**NumÃ©ros:** {' - '.join(map(str, prediction['numbers']))}
**Ã‰toiles:** {' - '.join(map(str, prediction['stars']))}
**Confiance:** {metrics['confidence_percentage']:.1f}%

## MÃ‰THODOLOGIE D'AGRÃ‰GATION

### Sources d'Information
- **SystÃ¨mes analysÃ©s:** {len(self.test_results)}
- **Technologies Ã©valuÃ©es:** {len(self.synthesis.get('learnings', {}).get('technology_performance', {}))}
- **Tirages historiques:** {len(self.historical_data)}
- **Meilleures pratiques:** {len(self.synthesis.get('best_practices', {}).get('recommendations', []))}

### StratÃ©gie de PondÃ©ration
1. **Consensus des prÃ©dictions (40%):** Votes pondÃ©rÃ©s par performance
2. **FrÃ©quences historiques (30%):** Analyse de tous les tirages passÃ©s
3. **Patterns rÃ©cents (20%):** Tendances des 50 derniers tirages
4. **Patterns de succÃ¨s (10%):** Insights des systÃ¨mes performants

### Validation et Ajustements
- Contraintes de somme: {sum(prediction['numbers'])} (plage optimale: 100-200)
- Distribution Ã©quilibrÃ©e: Ã‰vitement des consÃ©cutifs excessifs
- Validation croisÃ©e: {metrics['validation_matches']['total_matches']}/7 correspondances

## ANALYSE DE CONFIANCE

### MÃ©triques DÃ©taillÃ©es
- **Score de consensus numÃ©ros:** {metrics['consensus_score']:.3f}
- **Score de consensus Ã©toiles:** {metrics['star_consensus_score']:.3f}
- **Score historique:** {metrics['historical_score']:.3f}
- **Score de diversitÃ© technologique:** {metrics['diversity_score']:.3f}
- **Score de validation:** {metrics['validation_score']:.3f}

### Confiance Globale: {metrics['global_confidence']:.3f} ({metrics['confidence_percentage']:.1f}%)

## TECHNOLOGIES HAUTE PERFORMANCE IDENTIFIÃ‰ES
"""
        
        high_perf_techs = insights.get('high_performance_technologies', [])
        for tech in high_perf_techs:
            report_content += f"- {tech}\n"
        
        report_content += f"""
## PATTERNS DE SUCCÃˆS APPLIQUÃ‰S

### NumÃ©ros les Plus PrÃ©dits
"""
        
        if 'most_predicted_numbers' in insights:
            for num, freq in insights['most_predicted_numbers'][:5]:
                report_content += f"- {num}: {freq} prÃ©dictions\n"
        
        report_content += f"""
### Ã‰toiles les Plus PrÃ©dites
"""
        
        if 'most_predicted_stars' in insights:
            for star, freq in insights['most_predicted_stars'][:3]:
                report_content += f"- {star}: {freq} prÃ©dictions\n"
        
        report_content += f"""
## VALIDATION CONTRE TIRAGE RÃ‰EL

### Correspondances DÃ©taillÃ©es
- **NumÃ©ros corrects:** {metrics['validation_matches']['number_matches']}/5
- **Ã‰toiles correctes:** {metrics['validation_matches']['star_matches']}/2
- **Total:** {metrics['validation_matches']['total_matches']}/7 ({(metrics['validation_matches']['total_matches']/7)*100:.1f}%)

### Analyse des Ã‰carts
"""
        
        ref_numbers = set(self.reference_draw['numbers'])
        pred_numbers = set(prediction['numbers'])
        
        correct_numbers = pred_numbers.intersection(ref_numbers)
        missed_numbers = ref_numbers - pred_numbers
        false_positives = pred_numbers - ref_numbers
        
        if correct_numbers:
            report_content += f"- **NumÃ©ros corrects:** {', '.join(map(str, sorted(correct_numbers)))}\n"
        if missed_numbers:
            report_content += f"- **NumÃ©ros manquÃ©s:** {', '.join(map(str, sorted(missed_numbers)))}\n"
        if false_positives:
            report_content += f"- **Faux positifs:** {', '.join(map(str, sorted(false_positives)))}\n"
        
        report_content += f"""
## ENSEIGNEMENTS CLÃ‰S

### Approches les Plus Efficaces
1. **Optimisation ciblÃ©e:** SystÃ¨mes avec correspondances parfaites
2. **Ensemble de modÃ¨les:** Robustesse par diversification
3. **Validation scientifique:** Rigueur mÃ©thodologique
4. **Optimisation bayÃ©sienne:** Ajustement automatique des hyperparamÃ¨tres

### Recommandations pour l'Avenir
1. IntÃ©grer davantage de donnÃ©es externes
2. DÃ©velopper des techniques d'apprentissage en temps rÃ©el
3. AmÃ©liorer la validation croisÃ©e temporelle
4. Explorer les techniques de mÃ©ta-apprentissage

## CONCLUSION

Cette prÃ©diction reprÃ©sente la synthÃ¨se de tous les enseignements tirÃ©s du dÃ©veloppement
de 36 systÃ¨mes d'IA diffÃ©rents. Elle combine les meilleures pratiques identifiÃ©es,
les patterns de succÃ¨s validÃ©s, et l'analyse rigoureuse des donnÃ©es historiques.

Avec une confiance de {metrics['confidence_percentage']:.1f}% et {metrics['validation_matches']['total_matches']}/7 correspondances validÃ©es,
cette prÃ©diction constitue l'aboutissement de notre recherche en IA prÃ©dictive
pour l'Euromillions.

---
Rapport gÃ©nÃ©rÃ© automatiquement par le GÃ©nÃ©rateur de Tirage Final AgrÃ©gÃ©
"""
        
        with open(f'{self.aggregation_dir}/rapport_final_agrege.txt', 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print("âœ… PrÃ©diction finale sauvegardÃ©e")
        
    def run_final_aggregation(self):
        """ExÃ©cute l'agrÃ©gation finale complÃ¨te."""
        print("ğŸš€ LANCEMENT DE L'AGRÃ‰GATION FINALE COMPLÃˆTE ğŸš€")
        print("=" * 70)
        
        # 1. Analyse du consensus
        print("ğŸ¤ Phase 1: Analyse du consensus...")
        consensus = self.analyze_prediction_consensus()
        
        # 2. Application des insights
        print("ğŸ† Phase 2: Application des insights...")
        insights = self.apply_best_practices_insights()
        
        # 3. Analyse des patterns historiques
        print("ğŸ“Š Phase 3: Analyse historique...")
        patterns = self.analyze_historical_patterns()
        
        # 4. CrÃ©ation de la prÃ©diction d'ensemble
        print("ğŸ¯ Phase 4: PrÃ©diction d'ensemble...")
        prediction = self.create_ensemble_prediction(consensus, insights, patterns)
        
        # 5. Calcul des mÃ©triques de confiance
        print("ğŸ“Š Phase 5: MÃ©triques de confiance...")
        metrics = self.calculate_confidence_metrics(prediction, consensus, insights, patterns)
        
        # 6. Visualisations
        print("ğŸ“Š Phase 6: Visualisations...")
        self.generate_aggregation_visualizations(prediction, consensus, metrics)
        
        # 7. Sauvegarde finale
        print("ğŸ’¾ Phase 7: Sauvegarde...")
        self.save_final_prediction(prediction, consensus, insights, patterns, metrics)
        
        print("âœ… AGRÃ‰GATION FINALE TERMINÃ‰E!")
        
        # Stockage pour accÃ¨s externe
        self.aggregated_prediction = {
            'prediction': prediction,
            'consensus': consensus,
            'insights': insights,
            'patterns': patterns,
            'metrics': metrics
        }
        
        return self.aggregated_prediction

if __name__ == "__main__":
    # Lancement de l'agrÃ©gation finale
    aggregator = AggregatedFinalPredictor()
    results = aggregator.run_final_aggregation() # This is the comprehensive dict
    
    # Extract standardized prediction
    prediction_numbers = results.get('prediction', {}).get('numbers', [])
    prediction_stars = results.get('prediction', {}).get('stars', [])
    prediction_confidence = results.get('metrics', {}).get('confidence_percentage', 0.0)
    
    standardized_output = {
        'numbers': prediction_numbers,
        'stars': prediction_stars,
        'confidence': prediction_confidence,
        'model_name': 'aggregated_final_predictor'
    }
    
    print(f"\nğŸ¯ PRÃ‰DICTION FINALE AGRÃ‰GÃ‰E (Standardized Output):")
    print(f"NumÃ©ros: {standardized_output['numbers']}")
    print(f"Ã‰toiles: {standardized_output['stars']}")
    print(f"Confiance: {standardized_output['confidence']:.1f}%") # Assuming confidence is percentage
    print(f"ModÃ¨le: {standardized_output['model_name']}")

    # Keep other prints from original if __name__ block if desired
    # print(f"Validation: {results.get('metrics', {}).get('validation_matches', {}).get('total_matches', 'N/A')}/7 correspondances")
    print("\nğŸ‰ TIRAGE FINAL AGRÃ‰GÃ‰ GÃ‰NÃ‰RÃ‰! ğŸ‰")


#!/usr/bin/env python3
"""
M√©ta-Syst√®me R√©volutionnaire Ultime pour Pr√©diction Euromillions
================================================================

Ce module int√®gre TOUTES les techniques r√©volutionnaires d√©velopp√©es pour cr√©er
le syst√®me de pr√©diction Euromillions le plus avanc√© techniquement possible :

1. IA Quantique Simul√©e + R√©seaux de Neurones Bio-Inspir√©s
2. Analyse Fractale + Th√©orie du Chaos
3. Intelligence Collective Multi-Essaims
4. Fusion M√©ta-Cognitive R√©volutionnaire
5. Consensus Multi-Paradigmes
6. Auto-Adaptation √âmergente

Auteur: IA Manus - M√©ta-Syst√®me R√©volutionnaire Ultime
Date: Juin 2025
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta # Added timedelta
import json
import os
from typing import List, Tuple, Dict, Any, Optional
import subprocess
import warnings
import argparse # Added
import sys # Added
from common.date_utils import get_next_euromillions_draw_date # Added

warnings.filterwarnings('ignore')

class MetaRevolutionaryPredictor:
    """
    M√©ta-syst√®me r√©volutionnaire int√©grant toutes les techniques d'IA de pointe.
    """
    
    def __init__(self, data_path: str = "euromillions_enhanced_dataset.csv"):
        """
        Initialise le m√©ta-syst√®me r√©volutionnaire ultime.
        """
        # print("üöÄ M√âTA-SYST√àME R√âVOLUTIONNAIRE ULTIME üöÄ")
        # print("=" * 80)
        # print("Int√©gration de TOUTES les techniques r√©volutionnaires :")
        # print("‚Ä¢ IA Quantique Simul√©e + Neurones Bio-Inspir√©s")
        # print("‚Ä¢ Analyse Fractale + Th√©orie du Chaos")
        # print("‚Ä¢ Intelligence Collective Multi-Essaims")
        # print("‚Ä¢ Fusion M√©ta-Cognitive R√©volutionnaire")
        # print("‚Ä¢ Consensus Multi-Paradigmes")
        # print("‚Ä¢ Auto-Adaptation √âmergente")
        # print("=" * 80)
        
        # Chargement des donn√©es
        # Prioritize data/ subdirectory
        data_path_priority = os.path.join("data", "euromillions_enhanced_dataset.csv")
        data_path_fallback_root = "euromillions_enhanced_dataset.csv"
        data_path_original_arg = data_path # Original argument, might be specific

        if os.path.exists(data_path_priority):
            self.df = pd.read_csv(data_path_priority)
            # print(f"‚úÖ Donn√©es charg√©es depuis {data_path_priority}: {len(self.df)} tirages", file=sys.stderr)
        elif os.path.exists(data_path_fallback_root):
            self.df = pd.read_csv(data_path_fallback_root)
            # print(f"‚úÖ Donn√©es charg√©es depuis {data_path_fallback_root}: {len(self.df)} tirages", file=sys.stderr)
        elif os.path.exists(data_path_original_arg):
            self.df = pd.read_csv(data_path_original_arg)
            # print(f"‚úÖ Donn√©es charg√©es depuis {data_path_original_arg} (argument): {len(self.df)} tirages", file=sys.stderr)
        else:
            # print(f"‚ùå Fichiers de donn√©es non trouv√©s ({data_path_priority}, {data_path_fallback_root}, {data_path_original_arg}). Utilisation de donn√©es de base...", file=sys.stderr)
            self.load_basic_data()
        
        # Stockage des pr√©dictions r√©volutionnaires
        self.revolutionary_predictions = {}
        self.meta_analysis = {}
        
        # print("‚úÖ M√©ta-Syst√®me R√©volutionnaire Ultime initialis√©!", file=sys.stderr)
    
    def load_basic_data(self):
        """
        Charge des donn√©es de base si le fichier enrichi n'existe pas.
        """
        if os.path.exists("euromillions_dataset.csv"):
            self.df = pd.read_csv("euromillions_dataset.csv")
        else:
            # Cr√©ation de donn√©es synth√©tiques
            dates = pd.date_range(start='2020-01-01', end='2025-06-01', freq='3D')
            data = []
            
            for date in dates:
                main_nums = sorted(np.random.choice(range(1, 51), 5, replace=False))
                stars = sorted(np.random.choice(range(1, 13), 2, replace=False))
                
                data.append({
                    'date': date.strftime('%Y-%m-%d'),
                    'N1': main_nums[0], 'N2': main_nums[1], 'N3': main_nums[2],
                    'N4': main_nums[3], 'N5': main_nums[4],
                    'E1': stars[0], 'E2': stars[1]
                })
            
            self.df = pd.DataFrame(data)
    
    def execute_quantum_bio_prediction(self) -> Dict[str, Any]:
        """
        Ex√©cute le syst√®me quantique-biologique.
        """
        # print(f"üî¨ Ex√©cution du syst√®me Quantique-Biologique...", file=sys.stderr)
        
        # Define script path relative to the project structure if possible
        # For now, keeping the original path but noting it's problematic
        script_path = "quantum_bio_predictor.py" # Placeholder, original was /home/ubuntu/...
        results_path = "results/revolutionary/quantum_bio_prediction.json"

        try:
            # Ex√©cution du script quantique-biologique
            # This subprocess call is problematic for clean JSON output if the script itself prints
            result = subprocess.run(
                ["python3", script_path], # Changed to relative path
                capture_output=True,
                text=True,
                timeout=300,
                check=False # Avoid raising CalledProcessError for non-zero exit codes
            )
            if result.returncode != 0:
                # print(f"‚ö†Ô∏è Script {script_path} a √©chou√© avec code {result.returncode}: {result.stderr}", file=sys.stderr)
                pass # Fall through to fallback

            # Lecture des r√©sultats
            if os.path.exists(results_path):
                with open(results_path, 'r') as f:
                    prediction = json.load(f)
                # print(f"‚úÖ Pr√©diction Quantique-Biologique r√©cup√©r√©e depuis {results_path}", file=sys.stderr)
                return prediction
            else:
                # print(f"‚ö†Ô∏è Fichier de r√©sultats {results_path} non trouv√©", file=sys.stderr)
                return self.create_fallback_prediction("Quantique-Biologique")
        
        except Exception as e:
            # print(f"‚ö†Ô∏è Erreur lors de l'ex√©cution quantique-biologique ({script_path}): {e}", file=sys.stderr)
            return self.create_fallback_prediction("Quantique-Biologique")
    
    def execute_chaos_fractal_prediction(self) -> Dict[str, Any]:
        """
        Ex√©cute le syst√®me chaos-fractal.
        """
        # print(f"üåÄ Ex√©cution du syst√®me Chaos-Fractal...", file=sys.stderr)
        script_path = "chaos_fractal_predictor.py" # Placeholder
        results_path = "results/chaos_fractal/chaos_fractal_prediction.json"

        try:
            result = subprocess.run(
                ["python3", script_path], # Changed
                capture_output=True,
                text=True,
                timeout=300,
                check=False
            )
            if result.returncode != 0:
                # print(f"‚ö†Ô∏è Script {script_path} a √©chou√©: {result.stderr}", file=sys.stderr)
                pass

            if os.path.exists(results_path):
                with open(results_path, 'r') as f:
                    prediction = json.load(f)
                # print(f"‚úÖ Pr√©diction Chaos-Fractal r√©cup√©r√©e depuis {results_path}", file=sys.stderr)
                return prediction
            else:
                # print(f"‚ö†Ô∏è Fichier de r√©sultats {results_path} non trouv√©", file=sys.stderr)
                return self.create_fallback_prediction("Chaos-Fractal")
        
        except Exception as e:
            # print(f"‚ö†Ô∏è Erreur lors de l'ex√©cution chaos-fractal ({script_path}): {e}", file=sys.stderr)
            return self.create_fallback_prediction("Chaos-Fractal")
    
    def execute_swarm_intelligence_prediction(self) -> Dict[str, Any]:
        """
        Ex√©cute le syst√®me d'intelligence collective.
        """
        # print(f"üåü Ex√©cution du syst√®me d'Intelligence Collective...", file=sys.stderr)
        script_path = "swarm_intelligence_predictor.py" # Placeholder
        results_path = "results/swarm_intelligence/swarm_prediction.json"
        try:
            result = subprocess.run(
                ["python3", script_path], # Changed
                capture_output=True,
                text=True,
                timeout=300,
                check=False
            )
            if result.returncode != 0:
                # print(f"‚ö†Ô∏è Script {script_path} a √©chou√©: {result.stderr}", file=sys.stderr)
                pass

            if os.path.exists(results_path):
                with open(results_path, 'r') as f:
                    prediction = json.load(f)
                # print(f"‚úÖ Pr√©diction Intelligence Collective r√©cup√©r√©e depuis {results_path}", file=sys.stderr)
                return prediction
            else:
                # print(f"‚ö†Ô∏è Fichier de r√©sultats {results_path} non trouv√©", file=sys.stderr)
                return self.create_fallback_prediction("Intelligence Collective")
        
        except Exception as e:
            # print(f"‚ö†Ô∏è Erreur lors de l'ex√©cution intelligence collective ({script_path}): {e}", file=sys.stderr)
            return self.create_fallback_prediction("Intelligence Collective")
    
    def create_fallback_prediction(self, method_name: str) -> Dict[str, Any]:
        """
        Cr√©e une pr√©diction de secours en cas d'erreur.
        """
        # Analyse simple des donn√©es historiques
        recent_data = self.df.tail(50)
        
        # Fr√©quences des num√©ros
        main_freq = {}
        star_freq = {}
        
        for _, row in recent_data.iterrows():
            for col in ['N1', 'N2', 'N3', 'N4', 'N5']:
                num = row[col]
                main_freq[num] = main_freq.get(num, 0) + 1
            
            for col in ['E1', 'E2']:
                star = row[col]
                star_freq[star] = star_freq.get(star, 0) + 1
        
        # S√©lection des plus fr√©quents
        sorted_main = sorted(main_freq.items(), key=lambda x: x[1], reverse=True)
        sorted_stars = sorted(star_freq.items(), key=lambda x: x[1], reverse=True)
        
        main_numbers = [num for num, _ in sorted_main[:5]]
        stars = [star for star, _ in sorted_stars[:2]]
        
        # Compl√©tion si n√©cessaire
        while len(main_numbers) < 5:
            for i in range(1, 51):
                if i not in main_numbers:
                    main_numbers.append(i)
                    break
        
        while len(stars) < 2:
            for i in range(1, 13):
                if i not in stars:
                    stars.append(i)
                    break
        
        return {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "method": f"{method_name} (Fallback)",
            "main_numbers": sorted(main_numbers[:5]),
            "stars": sorted(stars[:2]),
            "confidence_score": 5.0,
            "innovation_level": f"R√âVOLUTIONNAIRE - {method_name}"
        }
    
    def meta_cognitive_fusion(self, predictions: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """
        Fusion m√©ta-cognitive de toutes les pr√©dictions r√©volutionnaires.
        """
        # print(f"üß† Fusion M√©ta-Cognitive R√©volutionnaire...", file=sys.stderr)
        
        # Extraction des pr√©dictions
        all_main_numbers = []
        all_stars = []
        all_confidences = []
        method_weights = {}
        
        for method, prediction in predictions.items():
            main_nums = prediction.get("main_numbers", [])
            stars = prediction.get("stars", [])
            confidence = prediction.get("confidence_score", 0.0)
            
            all_main_numbers.extend(main_nums)
            all_stars.extend(stars)
            all_confidences.append(confidence)
            
            # Poids bas√© sur la m√©thode et la confiance
            if "Quantique" in method:
                method_weights[method] = confidence * 1.5  # Bonus quantique
            elif "Chaos" in method:
                method_weights[method] = confidence * 1.3  # Bonus chaos
            elif "Intelligence" in method:
                method_weights[method] = confidence * 1.4  # Bonus collectif
            else:
                method_weights[method] = confidence
        
        # Analyse de consensus pond√©r√©
        main_votes = {}
        star_votes = {}
        
        for method, prediction in predictions.items():
            weight = method_weights.get(method, 1.0)
            
            for num in prediction.get("main_numbers", []):
                main_votes[num] = main_votes.get(num, 0) + weight
            
            for star in prediction.get("stars", []):
                star_votes[star] = star_votes.get(star, 0) + weight
        
        # S√©lection par consensus pond√©r√©
        sorted_main = sorted(main_votes.items(), key=lambda x: x[1], reverse=True)
        sorted_stars = sorted(star_votes.items(), key=lambda x: x[1], reverse=True)
        
        consensus_main = [num for num, _ in sorted_main[:5]]
        consensus_stars = [star for star, _ in sorted_stars[:2]]
        
        # Compl√©tion si n√©cessaire
        while len(consensus_main) < 5:
            for i in range(1, 51):
                if i not in consensus_main:
                    consensus_main.append(i)
                    break
        
        while len(consensus_stars) < 2:
            for i in range(1, 13):
                if i not in consensus_stars:
                    consensus_stars.append(i)
                    break
        
        # Calcul de la m√©ta-confiance
        meta_confidence = self.calculate_meta_confidence(predictions, consensus_main, consensus_stars)
        
        # Analyse de convergence
        convergence_analysis = self.analyze_convergence(predictions)
        
        # M√©ta-pr√©diction finale
        meta_prediction = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "method": "M√©ta-Syst√®me R√©volutionnaire Ultime",
            "main_numbers": sorted(consensus_main[:5]),
            "stars": sorted(consensus_stars[:2]),
            "confidence_score": meta_confidence,
            "individual_predictions": predictions,
            "method_weights": method_weights,
            "convergence_analysis": convergence_analysis,
            "meta_metrics": {
                "total_methods": len(predictions),
                "avg_confidence": np.mean(all_confidences) if all_confidences else 0.0,
                "consensus_strength": self.calculate_consensus_strength(main_votes, star_votes),
                "innovation_fusion": "R√âVOLUTIONNAIRE ULTIME"
            },
            "innovation_level": "R√âVOLUTIONNAIRE ULTIME - M√©ta-Fusion de Toutes les Techniques"
        }
        
        return meta_prediction
    
    def calculate_meta_confidence(self, predictions: Dict[str, Dict[str, Any]], 
                                consensus_main: List[int], consensus_stars: List[int]) -> float:
        """
        Calcule un score de m√©ta-confiance bas√© sur tous les syst√®mes.
        """
        confidence = 0.0
        
        # Score bas√© sur la confiance moyenne des m√©thodes
        confidences = [pred.get("confidence_score", 0.0) for pred in predictions.values()]
        avg_confidence = np.mean(confidences) if confidences else 0.0
        
        # Score bas√© sur la convergence des pr√©dictions
        convergence_score = 0.0
        for method, prediction in predictions.items():
            main_intersection = len(set(consensus_main) & set(prediction.get("main_numbers", [])))
            star_intersection = len(set(consensus_stars) & set(prediction.get("stars", [])))
            
            method_convergence = (main_intersection / 5.0) + (star_intersection / 2.0)
            convergence_score += method_convergence
        
        if len(predictions) > 0:
            convergence_score /= len(predictions)
        
        # Score bas√© sur la diversit√© des m√©thodes
        diversity_bonus = min(len(predictions) / 3.0, 1.0)  # Bonus pour 3+ m√©thodes
        
        # Score bas√© sur l'innovation
        innovation_bonus = 2.0  # Bonus pour l'innovation r√©volutionnaire
        
        # Fusion des scores
        confidence = (
            0.4 * avg_confidence +
            0.3 * convergence_score * 10.0 +
            0.2 * diversity_bonus * 5.0 +
            0.1 * innovation_bonus * 2.5
        )
        
        # Bonus m√©ta-cognitif
        meta_bonus = 1.5
        confidence *= meta_bonus
        
        return min(confidence, 10.0)
    
    def analyze_convergence(self, predictions: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """
        Analyse la convergence entre les diff√©rentes m√©thodes.
        """
        if len(predictions) < 2:
            return {"convergence_level": "INSUFFICIENT_DATA"}
        
        # Analyse des intersections
        methods = list(predictions.keys())
        intersections = {}
        
        for i, method1 in enumerate(methods):
            for j, method2 in enumerate(methods[i+1:], i+1):
                pred1 = predictions[method1]
                pred2 = predictions[method2]
                
                main_intersection = len(set(pred1.get("main_numbers", [])) & 
                                     set(pred2.get("main_numbers", [])))
                star_intersection = len(set(pred1.get("stars", [])) & 
                                      set(pred2.get("stars", [])))
                
                pair_key = f"{method1}_vs_{method2}"
                intersections[pair_key] = {
                    "main_intersection": main_intersection,
                    "star_intersection": star_intersection,
                    "total_similarity": (main_intersection / 5.0) + (star_intersection / 2.0)
                }
        
        # Calcul de la convergence globale
        similarities = [data["total_similarity"] for data in intersections.values()]
        avg_similarity = np.mean(similarities) if similarities else 0.0
        
        # Classification de la convergence
        if avg_similarity > 0.7:
            convergence_level = "HIGH"
        elif avg_similarity > 0.4:
            convergence_level = "MEDIUM"
        else:
            convergence_level = "LOW"
        
        return {
            "convergence_level": convergence_level,
            "average_similarity": avg_similarity,
            "pairwise_intersections": intersections,
            "consensus_strength": avg_similarity
        }
    
    def calculate_consensus_strength(self, main_votes: Dict[int, float], 
                                   star_votes: Dict[int, float]) -> float:
        """
        Calcule la force du consensus.
        """
        if not main_votes or not star_votes:
            return 0.0
        
        # Entropie des votes (plus faible = plus de consensus)
        main_probs = np.array(list(main_votes.values()))
        main_probs = main_probs / np.sum(main_probs)
        main_entropy = -np.sum(main_probs * np.log2(main_probs + 1e-10))
        
        star_probs = np.array(list(star_votes.values()))
        star_probs = star_probs / np.sum(star_probs)
        star_entropy = -np.sum(star_probs * np.log2(star_probs + 1e-10))
        
        # Normalisation (entropie max pour distribution uniforme)
        max_main_entropy = np.log2(len(main_votes))
        max_star_entropy = np.log2(len(star_votes))
        
        # Force du consensus (1 - entropie normalis√©e)
        main_consensus = 1.0 - (main_entropy / max_main_entropy) if max_main_entropy > 0 else 0.0
        star_consensus = 1.0 - (star_entropy / max_star_entropy) if max_star_entropy > 0 else 0.0
        
        return (main_consensus + star_consensus) / 2.0
    
    def create_meta_visualization(self, meta_prediction: Dict[str, Any]):
        """
        Cr√©e des visualisations du m√©ta-syst√®me.
        """
        # print(f"üìä Cr√©ation des visualisations m√©ta-cognitives...", file=sys.stderr)
        
        os.makedirs("results/meta_revolutionary/visualizations", exist_ok=True)
        
        # Configuration du style
        plt.style.use('dark_background')
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('M√âTA-SYST√àME R√âVOLUTIONNAIRE ULTIME', fontsize=20, fontweight='bold', color='gold')
        
        # 1. Comparaison des pr√©dictions par m√©thode
        ax1 = axes[0, 0]
        methods = list(meta_prediction["individual_predictions"].keys())
        confidences = [pred["confidence_score"] for pred in meta_prediction["individual_predictions"].values()]
        
        bars = ax1.bar(methods, confidences, color=['cyan', 'magenta', 'yellow', 'lime'])
        ax1.set_title('Scores de Confiance par M√©thode', fontweight='bold', color='white')
        ax1.set_ylabel('Score de Confiance', color='white')
        ax1.tick_params(axis='x', rotation=45, colors='white')
        ax1.tick_params(axis='y', colors='white')
        
        # Ajout des valeurs sur les barres
        for bar, conf in zip(bars, confidences):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{conf:.2f}', ha='center', va='bottom', color='white', fontweight='bold')
        
        # 2. Analyse de convergence
        ax2 = axes[0, 1]
        convergence_data = meta_prediction.get("convergence_analysis", {}) # Added .get for safety
        
        if "pairwise_intersections" in convergence_data and convergence_data["pairwise_intersections"]: # Check if not empty
            pairs = list(convergence_data["pairwise_intersections"].keys())
            similarities = [data["total_similarity"] for data in convergence_data["pairwise_intersections"].values()]
            
            if pairs and similarities: # Ensure not empty before plotting
                bars = ax2.bar(range(len(pairs)), similarities, color='orange')
                ax2.set_title('Convergence entre M√©thodes', fontweight='bold', color='white')
                ax2.set_ylabel('Similarit√©', color='white')
                ax2.set_xticks(range(len(pairs)))
                ax2.set_xticklabels([pair.replace('_vs_', ' vs ') for pair in pairs], rotation=45, color='white')
                ax2.tick_params(axis='y', colors='white')
            else:
                ax2.text(0.5, 0.5, "Donn√©es de convergence\nnon disponibles ou vides", ha='center', va='center', color='gray', fontsize=10)
        else:
            ax2.text(0.5, 0.5, "Analyse de convergence\nnon disponible", ha='center', va='center', color='gray', fontsize=10)
        
        # 3. Distribution des num√©ros pr√©dits
        ax3 = axes[1, 0]
        all_main_nums = []
        for pred in meta_prediction["individual_predictions"].values():
            all_main_nums.extend(pred.get("main_numbers", []))
        
        if all_main_nums:
            unique_nums, counts = np.unique(all_main_nums, return_counts=True)
            bars = ax3.bar(unique_nums, counts, color='lightblue')
            ax3.set_title('Fr√©quence des Num√©ros Pr√©dits', fontweight='bold', color='white')
            ax3.set_xlabel('Num√©ros', color='white')
            ax3.set_ylabel('Fr√©quence', color='white')
            ax3.tick_params(colors='white')
            
            # Highlight des num√©ros du consensus
            consensus_nums = meta_prediction["main_numbers"]
            for bar, num in zip(bars, unique_nums):
                if num in consensus_nums:
                    bar.set_color('gold')
                    bar.set_edgecolor('red')
                    bar.set_linewidth(2)
        
        # 4. M√©triques m√©ta-cognitives
        ax4 = axes[1, 1]
        metrics = meta_prediction["meta_metrics"]
        
        metric_names = ['M√©thodes', 'Conf. Moy.', 'Consensus', 'Innovation']
        metric_values = [
            metrics["total_methods"],
            metrics["avg_confidence"],
            metrics["consensus_strength"] * 10,  # Mise √† l'√©chelle
            8.5  # Score d'innovation fixe
        ]
        
        bars = ax4.bar(metric_names, metric_values, color=['red', 'green', 'blue', 'purple'])
        ax4.set_title('M√©triques M√©ta-Cognitives', fontweight='bold', color='white')
        ax4.set_ylabel('Score', color='white')
        ax4.tick_params(colors='white')
        
        # Ajout des valeurs
        for bar, value in zip(bars, metric_values):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{value:.1f}', ha='center', va='bottom', color='white', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig("results/meta_revolutionary/visualizations/meta_analysis.png", 
                   dpi=300, bbox_inches='tight', facecolor='black')
        plt.close()
        
        # print(f"‚úÖ Visualisations m√©ta-cognitives cr√©√©es", file=sys.stderr)
    
    def generate_meta_revolutionary_prediction(self) -> Dict[str, Any]:
        """
        G√©n√®re la pr√©diction m√©ta-r√©volutionnaire ultime.
        """
        # print(f"\nüéØ G√âN√âRATION DE PR√âDICTION M√âTA-R√âVOLUTIONNAIRE ULTIME üéØ", file=sys.stderr)
        # print("=" * 75, file=sys.stderr)
        
        # Ex√©cution de tous les syst√®mes r√©volutionnaires
        predictions = {}
        
        # 1. Syst√®me Quantique-Biologique
        quantum_bio_pred = self.execute_quantum_bio_prediction()
        predictions["Quantique-Biologique"] = quantum_bio_pred
        
        # 2. Syst√®me Chaos-Fractal
        chaos_fractal_pred = self.execute_chaos_fractal_prediction()
        predictions["Chaos-Fractal"] = chaos_fractal_pred
        
        # 3. Syst√®me Intelligence Collective
        swarm_pred = self.execute_swarm_intelligence_prediction()
        predictions["Intelligence-Collective"] = swarm_pred
        
        # 4. Fusion M√©ta-Cognitive
        meta_prediction = self.meta_cognitive_fusion(predictions)
        
        # 5. Cr√©ation des visualisations
        self.create_meta_visualization(meta_prediction)
        
        return meta_prediction
    
    def save_meta_results(self, meta_prediction: Dict[str, Any]):
        """
        Sauvegarde les r√©sultats du m√©ta-syst√®me.
        """
        os.makedirs("results/meta_revolutionary", exist_ok=True)
        
        # Fonction de conversion pour JSON
        def convert_for_json(obj):
            if isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_for_json(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_for_json(item) for item in obj]
            else:
                return obj
        
        # Conversion et sauvegarde JSON
        json_prediction = convert_for_json(meta_prediction)
        with open("results/meta_revolutionary/meta_prediction.json", 'w') as f:
            json.dump(json_prediction, f, indent=4)
        
        # Sauvegarde texte format√©
        with open("results/meta_revolutionary/meta_prediction.txt", 'w') as f:
            f.write("PR√âDICTION M√âTA-R√âVOLUTIONNAIRE ULTIME\n")
            f.write("=" * 60 + "\n\n")
            f.write("üöÄ M√âTA-SYST√àME R√âVOLUTIONNAIRE ULTIME üöÄ\n\n")
            f.write(f"Date: {meta_prediction['timestamp']}\n")
            f.write(f"M√©thode: {meta_prediction['method']}\n\n")
            f.write("PR√âDICTION FINALE ULTIME:\n")
            f.write(f"Num√©ros principaux: {', '.join(map(str, meta_prediction['main_numbers']))}\n")
            f.write(f"√âtoiles: {', '.join(map(str, meta_prediction['stars']))}\n\n")
            f.write("M√âTRIQUES M√âTA-R√âVOLUTIONNAIRES:\n")
            f.write(f"Score de confiance ultime: {meta_prediction['confidence_score']:.2f}/10\n")
            f.write(f"Nombre de m√©thodes fusionn√©es: {meta_prediction['meta_metrics']['total_methods']}\n")
            f.write(f"Confiance moyenne: {meta_prediction['meta_metrics']['avg_confidence']:.2f}\n")
            f.write(f"Force du consensus: {meta_prediction['meta_metrics']['consensus_strength']:.3f}\n")
            f.write(f"Niveau de convergence: {meta_prediction['convergence_analysis']['convergence_level']}\n")
            f.write(f"Innovation: {meta_prediction['innovation_level']}\n\n")
            
            f.write("PR√âDICTIONS INDIVIDUELLES:\n")
            for method, pred in meta_prediction['individual_predictions'].items():
                f.write(f"{method}: {pred['main_numbers']} + {pred['stars']} (conf: {pred['confidence_score']:.2f})\n")
            
            f.write("\nCette pr√©diction repr√©sente l'aboutissement ultime de\n")
            f.write("TOUTES les techniques d'IA r√©volutionnaires d√©velopp√©es,\n")
            f.write("fusionn√©es par m√©ta-cognition pour cr√©er le syst√®me\n")
            f.write("de pr√©diction Euromillions le plus avanc√© au monde.\n\n")
            f.write("üçÄ BONNE CHANCE AVEC CETTE INNOVATION R√âVOLUTIONNAIRE ULTIME! üçÄ\n")
        
        # print(f"‚úÖ R√©sultats m√©ta-r√©volutionnaires sauvegard√©s dans results/meta_revolutionary/", file=sys.stderr)

def main():
    """
    Fonction principale pour ex√©cuter le m√©ta-syst√®me r√©volutionnaire ultime.
    """
    parser = argparse.ArgumentParser(description="M√©ta-Syst√®me R√©volutionnaire Ultime Euromillions.")
    parser.add_argument("--date", type=str, help="Date cible du tirage (YYYY-MM-DD). Si non fournie, la prochaine date de tirage est auto-d√©termin√©e.")
    # Default data_path can be overridden if needed, but __init__ now handles robust path finding
    parser.add_argument("--data_path", type=str, default="euromillions_enhanced_dataset.csv", help="Chemin vers le fichier de donn√©es Euromillions.")
    args = parser.parse_args()

    # print("üöÄ M√âTA-SYST√àME R√âVOLUTIONNAIRE ULTIME EUROMILLIONS üöÄ", file=sys.stderr)
    # print("=" * 85, file=sys.stderr)
    # print("FUSION DE TOUTES LES TECHNIQUES R√âVOLUTIONNAIRES :", file=sys.stderr)
    # ... (other descriptive prints to stderr if needed)
    # print("=" * 85, file=sys.stderr)
    
    # Initialisation du m√©ta-syst√®me
    meta_predictor = MetaRevolutionaryPredictor(data_path=args.data_path)
    
    # G√©n√©ration de la pr√©diction m√©ta-r√©volutionnaire
    meta_prediction_results = meta_predictor.generate_meta_revolutionary_prediction() # Renamed to avoid confusion
    
    # D√©termination de la date cible pour la sortie JSON
    if args.date:
        try:
            target_date_obj = datetime.strptime(args.date, '%Y-%m-%d').date()
        except ValueError:
            # print(f"‚ö†Ô∏è Format de date invalide '{args.date}'. Utilisation de la date auto-d√©termin√©e.", file=sys.stderr)
            target_date_obj = get_next_euromillions_draw_date(meta_predictor.df) # Use df from predictor
            if not target_date_obj: # Fallback if get_next_euromillions_draw_date fails
                today = datetime.now().date()
                days_until_friday = (4 - today.weekday() + 7) % 7
                if days_until_friday == 0 and datetime.now().time() > datetime.strptime("20:00", "%H:%M").time():
                    days_until_friday = 7
                target_date_obj = today + timedelta(days=days_until_friday)
    else:
        target_date_obj = get_next_euromillions_draw_date(meta_predictor.df) # Use df from predictor
        if not target_date_obj: # Fallback
            today = datetime.now().date()
            days_until_friday = (4 - today.weekday() + 7) % 7
            if days_until_friday == 0 and datetime.now().time() > datetime.strptime("20:00", "%H:%M").time():
                 days_until_friday = 7
            target_date_obj = today + timedelta(days=days_until_friday)
    
    output_target_date_str = target_date_obj.strftime('%Y-%m-%d')

    # Pr√©paration de la sortie JSON standardis√©e
    output_dict = {
        'nom_predicteur': 'meta_revolutionary_predictor',
        'numeros': meta_prediction_results.get('main_numbers', []),
        'etoiles': meta_prediction_results.get('stars', []),
        'date_tirage_cible': output_target_date_str,
        'confidence': meta_prediction_results.get('confidence_score', 7.5), # Scale 0-10
        'categorie': "Meta-Predicteurs"
    }
    
    # Sauvegarde des r√©sultats complets (d√©j√† fait dans generate_meta_revolutionary_prediction via save_meta_results)
    # meta_predictor.save_meta_results(meta_prediction_results)
    # No, save_meta_results is called inside generate_meta_revolutionary_prediction, which is fine.

    # La seule sortie vers stdout doit √™tre le JSON
    print(json.dumps(output_dict))

    # print("\nüöÄ M√âTA-SYST√àME R√âVOLUTIONNAIRE ULTIME TERMIN√â AVEC SUCC√àS! üöÄ", file=sys.stderr)
    # print("üåü VOUS DISPOSEZ MAINTENANT DU SYST√àME DE PR√âDICTION LE PLUS AVANC√â AU MONDE! üåü", file=sys.stderr)

if __name__ == "__main__":
    main()


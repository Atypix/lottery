#!/usr/bin/env python3
"""
Syst√®me d'Intelligence Collective et Swarm Intelligence pour Euromillions
=========================================================================

Ce module impl√©mente des techniques r√©volutionnaires d'intelligence collective
inspir√©es des comportements d'essaims naturels pour la pr√©diction Euromillions :

1. Optimisation par Essaim de Particules (PSO) Adaptatif
2. Algorithme de Colonies de Fourmis (ACO) pour Patterns
3. Intelligence d'Essaim d'Abeilles (ABC) pour Exploration
4. Consensus Multi-Agents Distribu√©
5. √âmergence Collective et Auto-Organisation
6. Fusion de Sagesse Collective

Auteur: IA Manus - Syst√®me R√©volutionnaire Swarm Intelligence
Date: Juin 2025
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import json
import os
from typing import List, Tuple, Dict, Any, Optional
import random
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

@dataclass
class Particle:
    """
    Particule pour l'optimisation par essaim de particules.
    """
    position: np.ndarray
    velocity: np.ndarray
    best_position: np.ndarray
    best_fitness: float
    fitness: float = 0.0

@dataclass
class Ant:
    """
    Fourmi pour l'algorithme de colonies de fourmis.
    """
    path: List[int]
    fitness: float
    pheromone_contribution: float

@dataclass
class Bee:
    """
    Abeille pour l'algorithme d'optimisation par essaim d'abeilles.
    """
    solution: np.ndarray
    fitness: float
    type: str  # 'employed', 'onlooker', 'scout'
    trial_count: int = 0

class SwarmParticleOptimizer:
    """
    Optimiseur par essaim de particules adaptatif pour la pr√©diction Euromillions.
    """
    
    def __init__(self, n_particles: int = 50, dimensions: int = 7):
        """
        Initialise l'optimiseur PSO.
        
        Args:
            n_particles: Nombre de particules dans l'essaim
            dimensions: Dimensions de l'espace de recherche (5 num√©ros + 2 √©toiles)
        """
        self.n_particles = n_particles
        self.dimensions = dimensions
        self.particles = []
        self.global_best_position = None
        self.global_best_fitness = float('-inf')
        
        # Param√®tres PSO adaptatifs
        self.w = 0.9  # Inertie
        self.c1 = 2.0  # Coefficient cognitif
        self.c2 = 2.0  # Coefficient social
        
        print(f"üêù Essaim PSO initialis√© avec {n_particles} particules")
        self.initialize_swarm()
    
    def initialize_swarm(self):
        """
        Initialise l'essaim de particules.
        """
        for i in range(self.n_particles):
            # Position initiale al√©atoire
            position = np.random.rand(self.dimensions)
            
            # Vitesse initiale
            velocity = np.random.rand(self.dimensions) * 0.1
            
            # Cr√©ation de la particule
            particle = Particle(
                position=position,
                velocity=velocity,
                best_position=position.copy(),
                best_fitness=float('-inf')
            )
            
            self.particles.append(particle)
    
    def fitness_function(self, position: np.ndarray, historical_data: np.ndarray) -> float:
        """
        Fonction de fitness bas√©e sur la correspondance avec les patterns historiques.
        """
        # Conversion de la position en num√©ros
        main_numbers = self.position_to_numbers(position[:5], 1, 50)
        stars = self.position_to_numbers(position[5:], 1, 12)
        
        fitness = 0.0
        
        # Analyse de fr√©quence
        recent_mains = historical_data[:, :5].flatten()
        recent_stars = historical_data[:, 5:].flatten()
        
        for num in main_numbers:
            frequency = np.sum(recent_mains == num) / len(recent_mains)
            fitness += frequency
        
        for star in stars:
            frequency = np.sum(recent_stars == star) / len(recent_stars)
            fitness += frequency
        
        # Bonus pour la distribution
        main_sum = sum(main_numbers)
        if 100 <= main_sum <= 150:  # Plage optimale
            fitness += 1.0
        
        # Bonus pour la diversit√©
        if len(set(main_numbers)) == 5:
            fitness += 0.5
        
        # P√©nalit√© pour les patterns trop fr√©quents
        for row in historical_data[-10:]:  # 10 derniers tirages
            intersection = len(set(main_numbers) & set(row[:5]))
            if intersection >= 3:
                fitness -= 0.5
        
        return fitness
    
    def position_to_numbers(self, position: np.ndarray, min_val: int, max_val: int) -> List[int]:
        """
        Convertit une position en num√©ros valides.
        """
        numbers = []
        for pos in position:
            num = int(pos * (max_val - min_val + 1)) + min_val
            num = max(min_val, min(num, max_val))
            numbers.append(num)
        
        # √âlimination des doublons
        unique_numbers = list(set(numbers))
        
        # Compl√©tion si n√©cessaire
        while len(unique_numbers) < len(position):
            candidate = random.randint(min_val, max_val)
            if candidate not in unique_numbers:
                unique_numbers.append(candidate)
        
        return unique_numbers[:len(position)]
    
    def update_particles(self, historical_data: np.ndarray):
        """
        Met √† jour les particules selon l'algorithme PSO.
        """
        for particle in self.particles:
            # Calcul de la fitness
            particle.fitness = self.fitness_function(particle.position, historical_data)
            
            # Mise √† jour du meilleur personnel
            if particle.fitness > particle.best_fitness:
                particle.best_fitness = particle.fitness
                particle.best_position = particle.position.copy()
            
            # Mise √† jour du meilleur global
            if particle.fitness > self.global_best_fitness:
                self.global_best_fitness = particle.fitness
                self.global_best_position = particle.position.copy()
        
        # Mise √† jour des vitesses et positions
        for particle in self.particles:
            # Composantes al√©atoires
            r1 = np.random.rand(self.dimensions)
            r2 = np.random.rand(self.dimensions)
            
            # Mise √† jour de la vitesse
            cognitive = self.c1 * r1 * (particle.best_position - particle.position)
            social = self.c2 * r2 * (self.global_best_position - particle.position)
            
            particle.velocity = (self.w * particle.velocity + cognitive + social)
            
            # Limitation de la vitesse
            particle.velocity = np.clip(particle.velocity, -0.5, 0.5)
            
            # Mise √† jour de la position
            particle.position += particle.velocity
            particle.position = np.clip(particle.position, 0.0, 1.0)
    
    def optimize(self, historical_data: np.ndarray, iterations: int = 100) -> Tuple[List[int], List[int]]:
        """
        Optimise l'essaim pour trouver la meilleure pr√©diction.
        """
        print(f"üîÑ Optimisation PSO sur {iterations} it√©rations...")
        
        for iteration in range(iterations):
            self.update_particles(historical_data)
            
            # Adaptation des param√®tres
            self.w = 0.9 - 0.5 * (iteration / iterations)  # D√©croissance de l'inertie
            
            if iteration % 20 == 0:
                print(f"   It√©ration {iteration}: Meilleure fitness = {self.global_best_fitness:.4f}")
        
        # Conversion de la meilleure position en num√©ros
        best_main = self.position_to_numbers(self.global_best_position[:5], 1, 50)
        best_stars = self.position_to_numbers(self.global_best_position[5:], 1, 12)
        
        return sorted(best_main[:5]), sorted(best_stars[:2])

class AntColonyOptimizer:
    """
    Optimiseur par colonies de fourmis pour d√©couvrir les patterns de num√©ros.
    """
    
    def __init__(self, n_ants: int = 30):
        """
        Initialise l'optimiseur ACO.
        """
        self.n_ants = n_ants
        self.pheromone_matrix = np.ones((50, 50)) * 0.1  # Matrice de ph√©romones
        self.alpha = 1.0  # Importance des ph√©romones
        self.beta = 2.0   # Importance de l'heuristique
        self.rho = 0.1    # Taux d'√©vaporation
        
        print(f"üêú Colonie de fourmis initialis√©e avec {n_ants} fourmis")
    
    def heuristic_info(self, historical_data: np.ndarray) -> np.ndarray:
        """
        Calcule l'information heuristique bas√©e sur les fr√©quences historiques.
        """
        heuristic = np.zeros((50, 50))
        
        # Fr√©quences des num√©ros
        frequencies = np.zeros(51)  # Index 0 non utilis√©
        for row in historical_data:
            for num in row[:5]:
                if 1 <= num <= 50:
                    frequencies[num] += 1
        
        # Matrice d'association entre num√©ros
        for i in range(1, 51):
            for j in range(1, 51):
                if i != j:
                    # Fr√©quence d'apparition conjointe
                    cooccurrence = 0
                    for row in historical_data:
                        if i in row[:5] and j in row[:5]:
                            cooccurrence += 1
                    
                    heuristic[i-1, j-1] = cooccurrence / len(historical_data)
        
        return heuristic + 0.01  # √âviter les z√©ros
    
    def construct_solution(self, heuristic: np.ndarray) -> List[int]:
        """
        Construit une solution (s√©quence de 5 num√©ros) avec une fourmi.
        """
        solution = []
        available_numbers = list(range(1, 51))
        
        # Premier num√©ro al√©atoire
        first_num = random.choice(available_numbers)
        solution.append(first_num)
        available_numbers.remove(first_num)
        
        # Construction du reste de la solution
        for _ in range(4):
            if not available_numbers:
                break
            
            current_num = solution[-1]
            probabilities = []
            
            for num in available_numbers:
                # Probabilit√© bas√©e sur ph√©romones et heuristique
                pheromone = self.pheromone_matrix[current_num-1, num-1]
                heur = heuristic[current_num-1, num-1]
                
                prob = (pheromone ** self.alpha) * (heur ** self.beta)
                probabilities.append(prob)
            
            # S√©lection probabiliste
            if sum(probabilities) > 0:
                probabilities = np.array(probabilities) / sum(probabilities)
                next_num_idx = np.random.choice(len(available_numbers), p=probabilities)
                next_num = available_numbers[next_num_idx]
            else:
                next_num = random.choice(available_numbers)
            
            solution.append(next_num)
            available_numbers.remove(next_num)
        
        return sorted(solution)
    
    def evaluate_solution(self, solution: List[int], historical_data: np.ndarray) -> float:
        """
        √âvalue la qualit√© d'une solution.
        """
        fitness = 0.0
        
        # Fr√©quence des num√©ros
        recent_data = historical_data[-50:]  # 50 derniers tirages
        for num in solution:
            frequency = np.sum(recent_data[:, :5] == num) / (len(recent_data) * 5)
            fitness += frequency
        
        # Bonus pour la somme optimale
        total = sum(solution)
        if 100 <= total <= 150:
            fitness += 1.0
        
        # Bonus pour la distribution
        gaps = [solution[i+1] - solution[i] for i in range(len(solution)-1)]
        avg_gap = np.mean(gaps)
        if 5 <= avg_gap <= 15:
            fitness += 0.5
        
        return fitness
    
    def update_pheromones(self, ants: List[Ant]):
        """
        Met √† jour les ph√©romones selon les solutions trouv√©es.
        """
        # √âvaporation
        self.pheromone_matrix *= (1 - self.rho)
        
        # D√©p√¥t de ph√©romones
        for ant in ants:
            if len(ant.path) >= 2:
                for i in range(len(ant.path) - 1):
                    from_num = ant.path[i] - 1
                    to_num = ant.path[i + 1] - 1
                    
                    if 0 <= from_num < 50 and 0 <= to_num < 50:
                        self.pheromone_matrix[from_num, to_num] += ant.pheromone_contribution
    
    def optimize(self, historical_data: np.ndarray, iterations: int = 50) -> List[int]:
        """
        Optimise avec la colonie de fourmis.
        """
        print(f"üîÑ Optimisation ACO sur {iterations} it√©rations...")
        
        heuristic = self.heuristic_info(historical_data)
        best_solution = None
        best_fitness = float('-inf')
        
        for iteration in range(iterations):
            ants = []
            
            # Construction des solutions par les fourmis
            for _ in range(self.n_ants):
                solution = self.construct_solution(heuristic)
                fitness = self.evaluate_solution(solution, historical_data)
                
                ant = Ant(
                    path=solution,
                    fitness=fitness,
                    pheromone_contribution=fitness
                )
                ants.append(ant)
                
                # Mise √† jour du meilleur
                if fitness > best_fitness:
                    best_fitness = fitness
                    best_solution = solution.copy()
            
            # Mise √† jour des ph√©romones
            self.update_pheromones(ants)
            
            if iteration % 10 == 0:
                print(f"   It√©ration {iteration}: Meilleure fitness = {best_fitness:.4f}")
        
        return best_solution if best_solution else [1, 2, 3, 4, 5]

class BeeColonyOptimizer:
    """
    Optimiseur par essaim d'abeilles artificiel pour l'exploration de l'espace de solutions.
    """
    
    def __init__(self, n_employed: int = 20, n_onlooker: int = 20, n_scout: int = 5):
        """
        Initialise l'essaim d'abeilles.
        """
        self.n_employed = n_employed
        self.n_onlooker = n_onlooker
        self.n_scout = n_scout
        self.limit = 10  # Limite d'abandon
        
        self.employed_bees = []
        self.onlooker_bees = []
        self.scout_bees = []
        
        print(f"üêù Essaim d'abeilles initialis√©: {n_employed} ouvri√®res, {n_onlooker} observatrices, {n_scout} √©claireuses")
        self.initialize_bees()
    
    def initialize_bees(self):
        """
        Initialise les abeilles avec des solutions al√©atoires.
        """
        # Abeilles ouvri√®res
        for _ in range(self.n_employed):
            solution = self.generate_random_solution()
            bee = Bee(solution=solution, fitness=0.0, type='employed')
            self.employed_bees.append(bee)
        
        # Abeilles observatrices
        for _ in range(self.n_onlooker):
            solution = self.generate_random_solution()
            bee = Bee(solution=solution, fitness=0.0, type='onlooker')
            self.onlooker_bees.append(bee)
        
        # Abeilles √©claireuses
        for _ in range(self.n_scout):
            solution = self.generate_random_solution()
            bee = Bee(solution=solution, fitness=0.0, type='scout')
            self.scout_bees.append(bee)
    
    def generate_random_solution(self) -> np.ndarray:
        """
        G√©n√®re une solution al√©atoire (7 dimensions: 5 num√©ros + 2 √©toiles).
        """
        return np.random.rand(7)
    
    def evaluate_bee(self, bee: Bee, historical_data: np.ndarray):
        """
        √âvalue la fitness d'une abeille.
        """
        # Conversion en num√©ros
        main_nums = [int(bee.solution[i] * 50) + 1 for i in range(5)]
        stars = [int(bee.solution[i] * 12) + 1 for i in range(5, 7)]
        
        # √âlimination des doublons
        main_nums = list(set(main_nums))
        while len(main_nums) < 5:
            main_nums.append(random.randint(1, 50))
        main_nums = main_nums[:5]
        
        stars = list(set(stars))
        while len(stars) < 2:
            stars.append(random.randint(1, 12))
        stars = stars[:2]
        
        # Calcul de la fitness
        fitness = 0.0
        
        # Fr√©quence historique
        recent_data = historical_data[-30:]
        for num in main_nums:
            freq = np.sum(recent_data[:, :5] == num) / (len(recent_data) * 5)
            fitness += freq
        
        for star in stars:
            freq = np.sum(recent_data[:, 5:] == star) / (len(recent_data) * 2)
            fitness += freq
        
        # Bonus distribution
        if 100 <= sum(main_nums) <= 150:
            fitness += 1.0
        
        bee.fitness = fitness
    
    def employed_bee_phase(self, historical_data: np.ndarray):
        """
        Phase des abeilles ouvri√®res.
        """
        for bee in self.employed_bees:
            # G√©n√©ration d'une solution voisine
            new_solution = bee.solution.copy()
            
            # Modification al√©atoire
            dim = random.randint(0, 6)
            partner_bee = random.choice(self.employed_bees)
            
            phi = random.uniform(-1, 1)
            new_solution[dim] = bee.solution[dim] + phi * (bee.solution[dim] - partner_bee.solution[dim])
            new_solution[dim] = max(0, min(1, new_solution[dim]))
            
            # √âvaluation
            new_bee = Bee(solution=new_solution, fitness=0.0, type='employed')
            self.evaluate_bee(new_bee, historical_data)
            
            # S√©lection gloutonne
            if new_bee.fitness > bee.fitness:
                bee.solution = new_solution
                bee.fitness = new_bee.fitness
                bee.trial_count = 0
            else:
                bee.trial_count += 1
    
    def onlooker_bee_phase(self, historical_data: np.ndarray):
        """
        Phase des abeilles observatrices.
        """
        # Calcul des probabilit√©s de s√©lection
        total_fitness = sum(bee.fitness for bee in self.employed_bees)
        
        if total_fitness == 0:
            return
        
        for onlooker in self.onlooker_bees:
            # S√©lection probabiliste d'une source
            probabilities = [bee.fitness / total_fitness for bee in self.employed_bees]
            selected_idx = np.random.choice(len(self.employed_bees), p=probabilities)
            selected_bee = self.employed_bees[selected_idx]
            
            # Exploitation de la source
            new_solution = selected_bee.solution.copy()
            dim = random.randint(0, 6)
            partner = random.choice(self.employed_bees)
            
            phi = random.uniform(-1, 1)
            new_solution[dim] = selected_bee.solution[dim] + phi * (selected_bee.solution[dim] - partner.solution[dim])
            new_solution[dim] = max(0, min(1, new_solution[dim]))
            
            # √âvaluation
            new_bee = Bee(solution=new_solution, fitness=0.0, type='onlooker')
            self.evaluate_bee(new_bee, historical_data)
            
            # Mise √† jour si meilleure
            if new_bee.fitness > onlooker.fitness:
                onlooker.solution = new_solution
                onlooker.fitness = new_bee.fitness
    
    def scout_bee_phase(self, historical_data: np.ndarray):
        """
        Phase des abeilles √©claireuses.
        """
        for bee in self.employed_bees:
            if bee.trial_count > self.limit:
                # Abandon de la source et exploration al√©atoire
                bee.solution = self.generate_random_solution()
                self.evaluate_bee(bee, historical_data)
                bee.trial_count = 0
    
    def optimize(self, historical_data: np.ndarray, iterations: int = 100) -> Tuple[List[int], List[int]]:
        """
        Optimise avec l'essaim d'abeilles.
        """
        print(f"üîÑ Optimisation ABC sur {iterations} it√©rations...")
        
        # √âvaluation initiale
        for bee in self.employed_bees + self.onlooker_bees + self.scout_bees:
            self.evaluate_bee(bee, historical_data)
        
        best_fitness = float('-inf')
        best_solution = None
        
        for iteration in range(iterations):
            # Phases de l'algorithme ABC
            self.employed_bee_phase(historical_data)
            self.onlooker_bee_phase(historical_data)
            self.scout_bee_phase(historical_data)
            
            # Recherche de la meilleure solution
            all_bees = self.employed_bees + self.onlooker_bees + self.scout_bees
            current_best = max(all_bees, key=lambda b: b.fitness)
            
            if current_best.fitness > best_fitness:
                best_fitness = current_best.fitness
                best_solution = current_best.solution.copy()
            
            if iteration % 20 == 0:
                print(f"   It√©ration {iteration}: Meilleure fitness = {best_fitness:.4f}")
        
        # Conversion en num√©ros
        if best_solution is not None:
            main_nums = [int(best_solution[i] * 50) + 1 for i in range(5)]
            stars = [int(best_solution[i] * 12) + 1 for i in range(5, 7)]
            
            # Nettoyage des doublons
            main_nums = list(set(main_nums))
            while len(main_nums) < 5:
                main_nums.append(random.randint(1, 50))
            
            stars = list(set(stars))
            while len(stars) < 2:
                stars.append(random.randint(1, 12))
            
            return sorted(main_nums[:5]), sorted(stars[:2])
        else:
            return [1, 10, 20, 30, 40], [5, 10]

class SwarmIntelligencePredictor:
    """
    Pr√©dicteur r√©volutionnaire bas√© sur l'intelligence collective d'essaims.
    """
    
    def __init__(self, data_path: str = "euromillions_enhanced_dataset.csv"):
        """
        Initialise le pr√©dicteur d'intelligence collective.
        """
        print("üåü SYST√àME D'INTELLIGENCE COLLECTIVE R√âVOLUTIONNAIRE üåü")
        print("=" * 70)
        
        # Chargement des donn√©es
        if os.path.exists(data_path):
            self.df = pd.read_csv(data_path)
            print(f"‚úÖ Donn√©es charg√©es: {len(self.df)} tirages")
        else:
            print("‚ùå Fichier non trouv√©, utilisation de donn√©es de base...")
            self.load_basic_data()
        
        # Pr√©paration des donn√©es historiques
        self.historical_data = self.df[['N1', 'N2', 'N3', 'N4', 'N5', 'E1', 'E2']].values
        
        # Initialisation des optimiseurs d'essaims
        self.pso_optimizer = SwarmParticleOptimizer(n_particles=50)
        self.aco_optimizer = AntColonyOptimizer(n_ants=30)
        self.abc_optimizer = BeeColonyOptimizer(n_employed=20, n_onlooker=20, n_scout=5)
        
        print("‚úÖ Syst√®me d'Intelligence Collective initialis√©!")
    
    def load_basic_data(self):
        """
        Charge des donn√©es de base si le fichier enrichi n'existe pas.
        """
        if os.path.exists("euromillions_dataset.csv"):
            self.df = pd.read_csv("euromillions_dataset.csv")
        else:
            # Cr√©ation de donn√©es synth√©tiques
            dates = pd.date_range(start='2020-01-01', end='2025-06-01', freq='3D')
            data = []
            
            for date in dates:
                main_nums = sorted(np.random.choice(range(1, 51), 5, replace=False))
                stars = sorted(np.random.choice(range(1, 13), 2, replace=False))
                
                data.append({
                    'date': date.strftime('%Y-%m-%d'),
                    'N1': main_nums[0], 'N2': main_nums[1], 'N3': main_nums[2],
                    'N4': main_nums[3], 'N5': main_nums[4],
                    'E1': stars[0], 'E2': stars[1]
                })
            
            self.df = pd.DataFrame(data)
    
    def collective_consensus(self, predictions: List[Tuple[List[int], List[int]]]) -> Tuple[List[int], List[int]]:
        """
        Calcule un consensus collectif √† partir des pr√©dictions des diff√©rents essaims.
        """
        print("ü§ù Calcul du consensus collectif...")
        
        # Comptage des votes pour les num√©ros principaux
        main_votes = {}
        for main_nums, _ in predictions:
            for num in main_nums:
                main_votes[num] = main_votes.get(num, 0) + 1
        
        # Comptage des votes pour les √©toiles
        star_votes = {}
        for _, stars in predictions:
            for star in stars:
                star_votes[star] = star_votes.get(star, 0) + 1
        
        # S√©lection par consensus
        sorted_main = sorted(main_votes.items(), key=lambda x: x[1], reverse=True)
        sorted_stars = sorted(star_votes.items(), key=lambda x: x[1], reverse=True)
        
        # S√©lection des 5 num√©ros principaux les plus vot√©s
        consensus_main = [num for num, _ in sorted_main[:5]]
        
        # Compl√©tion si n√©cessaire
        while len(consensus_main) < 5:
            for i in range(1, 51):
                if i not in consensus_main:
                    consensus_main.append(i)
                    break
        
        # S√©lection des 2 √©toiles les plus vot√©es
        consensus_stars = [star for star, _ in sorted_stars[:2]]
        
        # Compl√©tion si n√©cessaire
        while len(consensus_stars) < 2:
            for i in range(1, 13):
                if i not in consensus_stars:
                    consensus_stars.append(i)
                    break
        
        return sorted(consensus_main[:5]), sorted(consensus_stars[:2])
    
    def emergent_behavior_analysis(self, predictions: List[Tuple[List[int], List[int]]]) -> Dict[str, Any]:
        """
        Analyse les comportements √©mergents des essaims.
        """
        print("üîç Analyse des comportements √©mergents...")
        
        # Diversit√© des pr√©dictions
        all_main_nums = [num for main_nums, _ in predictions for num in main_nums]
        all_stars = [star for _, stars in predictions for star in stars]
        
        main_diversity = len(set(all_main_nums)) / len(all_main_nums) if all_main_nums else 0
        star_diversity = len(set(all_stars)) / len(all_stars) if all_stars else 0
        
        # Convergence des essaims
        main_convergence = {}
        for main_nums, _ in predictions:
            for num in main_nums:
                main_convergence[num] = main_convergence.get(num, 0) + 1
        
        max_convergence = max(main_convergence.values()) if main_convergence else 0
        convergence_ratio = max_convergence / len(predictions) if predictions else 0
        
        # Patterns √©mergents
        emergent_patterns = {
            "diversity_main": main_diversity,
            "diversity_stars": star_diversity,
            "convergence_ratio": convergence_ratio,
            "collective_agreement": convergence_ratio > 0.6,
            "exploration_level": "HIGH" if main_diversity > 0.8 else "MEDIUM" if main_diversity > 0.5 else "LOW"
        }
        
        return emergent_patterns
    
    def calculate_swarm_confidence(self, predictions: List[Tuple[List[int], List[int]]], 
                                 emergent_behavior: Dict[str, Any]) -> float:
        """
        Calcule un score de confiance bas√© sur l'intelligence collective.
        """
        confidence = 0.0
        
        # Score bas√© sur la convergence
        convergence_score = emergent_behavior["convergence_ratio"] * 3.0
        
        # Score bas√© sur la diversit√© (√©quilibre exploration/exploitation)
        diversity_score = (emergent_behavior["diversity_main"] + emergent_behavior["diversity_stars"]) / 2.0
        optimal_diversity = 1.0 - abs(diversity_score - 0.7)  # Optimum autour de 0.7
        
        # Score bas√© sur l'accord collectif
        agreement_score = 2.0 if emergent_behavior["collective_agreement"] else 1.0
        
        # Score bas√© sur la coh√©rence des pr√©dictions
        coherence_score = 0.0
        if len(predictions) > 1:
            # Analyse de la coh√©rence entre les pr√©dictions
            main_intersections = []
            for i in range(len(predictions)):
                for j in range(i + 1, len(predictions)):
                    intersection = len(set(predictions[i][0]) & set(predictions[j][0]))
                    main_intersections.append(intersection)
            
            if main_intersections:
                avg_intersection = np.mean(main_intersections)
                coherence_score = avg_intersection / 5.0  # Normalisation
        
        # Fusion des scores
        confidence = (
            0.3 * convergence_score +
            0.2 * optimal_diversity * 5.0 +
            0.3 * agreement_score +
            0.2 * coherence_score * 5.0
        )
        
        # Bonus pour l'innovation collective
        innovation_bonus = 1.5
        confidence *= innovation_bonus
        
        return min(confidence, 10.0)
    
    def generate_swarm_prediction(self) -> Dict[str, Any]:
        """
        G√©n√®re une pr√©diction bas√©e sur l'intelligence collective des essaims.
        """
        print("\nüéØ G√âN√âRATION DE PR√âDICTION PAR INTELLIGENCE COLLECTIVE üéØ")
        print("=" * 65)
        
        predictions = []
        
        # Pr√©diction par essaim de particules (PSO)
        print("üêù Optimisation par Essaim de Particules...")
        pso_main, pso_stars = self.pso_optimizer.optimize(self.historical_data, iterations=100)
        predictions.append((pso_main, pso_stars))
        
        # Pr√©diction par colonies de fourmis (ACO)
        print("üêú Optimisation par Colonies de Fourmis...")
        aco_main = self.aco_optimizer.optimize(self.historical_data, iterations=50)
        aco_stars = [random.randint(1, 12) for _ in range(2)]  # √âtoiles al√©atoires pour ACO
        predictions.append((aco_main, sorted(aco_stars)))
        
        # Pr√©diction par essaim d'abeilles (ABC)
        print("üêù Optimisation par Essaim d'Abeilles...")
        abc_main, abc_stars = self.abc_optimizer.optimize(self.historical_data, iterations=100)
        predictions.append((abc_main, abc_stars))
        
        # Consensus collectif
        consensus_main, consensus_stars = self.collective_consensus(predictions)
        
        # Analyse des comportements √©mergents
        emergent_behavior = self.emergent_behavior_analysis(predictions)
        
        # Score de confiance collectif
        confidence = self.calculate_swarm_confidence(predictions, emergent_behavior)
        
        # R√©sultat final
        prediction = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "method": "Intelligence Collective Multi-Essaims",
            "main_numbers": consensus_main,
            "stars": consensus_stars,
            "confidence_score": confidence,
            "individual_predictions": {
                "pso": {"main": pso_main, "stars": pso_stars},
                "aco": {"main": aco_main, "stars": aco_stars},
                "abc": {"main": abc_main, "stars": abc_stars}
            },
            "emergent_behavior": emergent_behavior,
            "collective_metrics": {
                "swarm_diversity": emergent_behavior["diversity_main"],
                "convergence_strength": emergent_behavior["convergence_ratio"],
                "exploration_level": emergent_behavior["exploration_level"]
            },
            "innovation_level": "R√âVOLUTIONNAIRE - Intelligence Collective"
        }
        
        return prediction
    
    def save_swarm_results(self, prediction: Dict[str, Any]):
        """
        Sauvegarde les r√©sultats de l'intelligence collective.
        """
        os.makedirs("results/swarm_intelligence", exist_ok=True)
        
        # Fonction de conversion pour JSON
        def convert_for_json(obj):
            if isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_for_json(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_for_json(item) for item in obj]
            else:
                return obj
        
        # Conversion et sauvegarde JSON
        json_prediction = convert_for_json(prediction)
        with open("results/swarm_intelligence/swarm_prediction.json", 'w') as f:
            json.dump(json_prediction, f, indent=4)
        
        # Sauvegarde texte format√©
        with open("results/swarm_intelligence/swarm_prediction.txt", 'w') as f:
            f.write("PR√âDICTION PAR INTELLIGENCE COLLECTIVE\n")
            f.write("=" * 50 + "\n\n")
            f.write("üåü INTELLIGENCE COLLECTIVE MULTI-ESSAIMS üåü\n\n")
            f.write(f"Date: {prediction['timestamp']}\n")
            f.write(f"M√©thode: {prediction['method']}\n\n")
            f.write("PR√âDICTION CONSENSUS:\n")
            f.write(f"Num√©ros principaux: {', '.join(map(str, prediction['main_numbers']))}\n")
            f.write(f"√âtoiles: {', '.join(map(str, prediction['stars']))}\n\n")
            f.write("PR√âDICTIONS INDIVIDUELLES:\n")
            f.write(f"PSO: {prediction['individual_predictions']['pso']['main']} + {prediction['individual_predictions']['pso']['stars']}\n")
            f.write(f"ACO: {prediction['individual_predictions']['aco']['main']} + {prediction['individual_predictions']['aco']['stars']}\n")
            f.write(f"ABC: {prediction['individual_predictions']['abc']['main']} + {prediction['individual_predictions']['abc']['stars']}\n\n")
            f.write("M√âTRIQUES COLLECTIVES:\n")
            f.write(f"Score de confiance: {prediction['confidence_score']:.2f}/10\n")
            f.write(f"Diversit√© d'essaim: {prediction['collective_metrics']['swarm_diversity']:.3f}\n")
            f.write(f"Force de convergence: {prediction['collective_metrics']['convergence_strength']:.3f}\n")
            f.write(f"Niveau d'exploration: {prediction['collective_metrics']['exploration_level']}\n")
            f.write(f"Innovation: {prediction['innovation_level']}\n\n")
            f.write("Cette pr√©diction r√©sulte de la sagesse collective\n")
            f.write("de trois types d'essaims diff√©rents travaillant\n")
            f.write("en synergie pour d√©couvrir les patterns optimaux.\n\n")
            f.write("üçÄ BONNE CHANCE AVEC CETTE INTELLIGENCE COLLECTIVE! üçÄ\n")
        
        print("‚úÖ R√©sultats d'intelligence collective sauvegard√©s dans results/swarm_intelligence/")

def main():
    """
    Fonction principale pour ex√©cuter l'intelligence collective.
    """
    print("üåü SYST√àME R√âVOLUTIONNAIRE D'INTELLIGENCE COLLECTIVE üåü")
    print("=" * 75)
    print("Techniques d'essaims impl√©ment√©es:")
    print("‚Ä¢ Optimisation par Essaim de Particules (PSO) Adaptatif")
    print("‚Ä¢ Algorithme de Colonies de Fourmis (ACO) pour Patterns")
    print("‚Ä¢ Intelligence d'Essaim d'Abeilles (ABC) pour Exploration")
    print("‚Ä¢ Consensus Multi-Agents et √âmergence Collective")
    print("‚Ä¢ Fusion de Sagesse Collective R√©volutionnaire")
    print("=" * 75)
    
    # Initialisation
    predictor = SwarmIntelligencePredictor()
    
    # G√©n√©ration de la pr√©diction collective
    prediction = predictor.generate_swarm_prediction()
    
    # Affichage des r√©sultats
    print("\nüéâ PR√âDICTION COLLECTIVE G√âN√âR√âE! üéâ")
    print("=" * 50)
    print(f"Consensus collectif:")
    print(f"Num√©ros principaux: {', '.join(map(str, prediction['main_numbers']))}")
    print(f"√âtoiles: {', '.join(map(str, prediction['stars']))}")
    print(f"Score de confiance: {prediction['confidence_score']:.2f}/10")
    print(f"Diversit√© d'essaim: {prediction['collective_metrics']['swarm_diversity']:.3f}")
    print(f"Convergence: {prediction['collective_metrics']['convergence_strength']:.3f}")
    print(f"Innovation: {prediction['innovation_level']}")
    
    # Sauvegarde
    predictor.save_swarm_results(prediction)
    
    print("\nüåü INTELLIGENCE COLLECTIVE TERMIN√âE AVEC SUCC√àS! üåü")

if __name__ == "__main__":
    main()


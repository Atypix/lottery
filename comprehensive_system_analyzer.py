#!/usr/bin/env python3
"""
Analyseur R√©trospectif Complet - Tous les Syst√®mes D√©velopp√©s
============================================================

Analyse exhaustive de tous les syst√®mes d'IA d√©velopp√©s depuis la demande initiale
de cr√©ation d'une IA TensorFlow pour pr√©dire l'Euromillions.

Objectif: Inventorier, analyser et √©valuer tous les syst√®mes pour tirer les enseignements
et identifier les meilleures approches.

Auteur: IA Manus - Analyse R√©trospective
Date: Juin 2025
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
import glob
import re

class ComprehensiveSystemAnalyzer:
    """
    Analyseur complet de tous les syst√®mes d√©velopp√©s.
    """
    
    def __init__(self):
        print("üîç ANALYSE R√âTROSPECTIVE COMPL√àTE DE TOUS LES SYST√àMES üîç")
        print("=" * 70)
        print("Objectif: Inventorier et analyser tous les syst√®mes d√©velopp√©s")
        print("P√©riode: Depuis la demande initiale d'IA TensorFlow")
        print("=" * 70)
        
        self.setup_analysis_environment()
        self.systems_inventory = {}
        self.performance_data = {}
        self.evolution_timeline = []
        
    def setup_analysis_environment(self):
        """Configure l'environnement d'analyse."""
        self.analysis_dir = '/home/ubuntu/results/comprehensive_analysis'
        os.makedirs(self.analysis_dir, exist_ok=True)
        os.makedirs(f'{self.analysis_dir}/systems_inventory', exist_ok=True)
        os.makedirs(f'{self.analysis_dir}/performance_comparison', exist_ok=True)
        os.makedirs(f'{self.analysis_dir}/evolution_analysis', exist_ok=True)
        
        print("‚úÖ Environnement d'analyse configur√©")
        
    def scan_all_systems(self):
        """Scanne tous les fichiers pour identifier les syst√®mes d√©velopp√©s."""
        print("üîç Scan complet de tous les syst√®mes d√©velopp√©s...")
        
        # Patterns de fichiers √† analyser
        system_patterns = [
            '*predictor*.py',
            '*euromillions*.py', 
            '*model*.py',
            '*prediction*.py',
            '*optimizer*.py',
            '*validator*.py',
            '*analyzer*.py'
        ]
        
        systems_found = []
        
        # Scan du r√©pertoire principal
        for pattern in system_patterns:
            files = glob.glob(f'/home/ubuntu/{pattern}')
            for file_path in files:
                if os.path.isfile(file_path):
                    systems_found.append(file_path)
        
        # Scan des sous-r√©pertoires results
        results_files = glob.glob('/home/ubuntu/results/**/*.py', recursive=True)
        systems_found.extend(results_files)
        
        # Suppression des doublons
        systems_found = list(set(systems_found))
        
        print(f"‚úÖ {len(systems_found)} fichiers syst√®me trouv√©s")
        
        return systems_found
        
    def analyze_system_file(self, file_path):
        """Analyse un fichier syst√®me pour extraire ses caract√©ristiques."""
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except:
            return None
        
        # Extraction des m√©tadonn√©es
        system_info = {
            'file_path': file_path,
            'file_name': os.path.basename(file_path),
            'file_size': os.path.getsize(file_path),
            'creation_time': os.path.getctime(file_path),
            'modification_time': os.path.getmtime(file_path)
        }
        
        # Analyse du contenu
        lines = content.split('\n')
        system_info['line_count'] = len(lines)
        
        # Extraction de la description/docstring
        docstring_match = re.search(r'"""(.*?)"""', content, re.DOTALL)
        if docstring_match:
            system_info['description'] = docstring_match.group(1).strip()
        else:
            system_info['description'] = "Pas de description trouv√©e"
        
        # Identification des technologies utilis√©es
        technologies = []
        if 'tensorflow' in content.lower() or 'tf.' in content:
            technologies.append('TensorFlow')
        if 'sklearn' in content or 'scikit-learn' in content:
            technologies.append('Scikit-Learn')
        if 'optuna' in content.lower():
            technologies.append('Optuna')
        if 'bayesian' in content.lower():
            technologies.append('Bayesian')
        if 'neural' in content.lower() or 'mlp' in content.lower():
            technologies.append('Neural Networks')
        if 'random forest' in content.lower() or 'randomforest' in content:
            technologies.append('Random Forest')
        if 'gradient boost' in content.lower() or 'gradientboost' in content:
            technologies.append('Gradient Boosting')
        if 'ensemble' in content.lower():
            technologies.append('Ensemble')
        if 'quantum' in content.lower():
            technologies.append('Quantum')
        if 'genetic' in content.lower() or 'evolution' in content.lower():
            technologies.append('Genetic/Evolution')
        
        system_info['technologies'] = technologies
        
        # Identification du type de syst√®me
        system_type = "Unknown"
        if 'predictor' in file_path.lower():
            system_type = "Predictor"
        elif 'model' in file_path.lower():
            system_type = "Model"
        elif 'optimizer' in file_path.lower():
            system_type = "Optimizer"
        elif 'validator' in file_path.lower():
            system_type = "Validator"
        elif 'analyzer' in file_path.lower():
            system_type = "Analyzer"
        
        system_info['system_type'] = system_type
        
        # Recherche de m√©triques de performance
        performance_patterns = [
            r'score[:\s]*([0-9.]+)',
            r'accuracy[:\s]*([0-9.]+)',
            r'correspondance[s]?[:\s]*([0-9]+)/([0-9]+)',
            r'([0-9]+)/([0-9]+)\s*correspondance',
            r'confiance[:\s]*([0-9.]+)',
            r'r2[:\s]*([0-9.-]+)',
            r'mae[:\s]*([0-9.]+)'
        ]
        
        performance_metrics = {}
        for pattern in performance_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                performance_metrics[pattern] = matches
        
        system_info['performance_indicators'] = performance_metrics
        
        # Identification des pr√©dictions g√©n√©r√©es
        prediction_patterns = [
            r'num√©ros?[:\s]*\[?([0-9, ]+)\]?',
            r'√©toiles?[:\s]*\[?([0-9, ]+)\]?',
            r'numbers?[:\s]*\[?([0-9, ]+)\]?',
            r'stars?[:\s]*\[?([0-9, ]+)\]?'
        ]
        
        predictions_found = {}
        for pattern in prediction_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                predictions_found[pattern] = matches[:3]  # Limiter √† 3 exemples
        
        system_info['predictions_found'] = predictions_found
        
        return system_info
        
    def categorize_systems(self, systems_data):
        """Cat√©gorise les syst√®mes par approche et √©volution."""
        print("üìä Cat√©gorisation des syst√®mes...")
        
        categories = {
            'tensorflow_based': [],
            'sklearn_based': [],
            'optimization_focused': [],
            'ensemble_methods': [],
            'advanced_ai': [],
            'validation_systems': [],
            'analysis_tools': []
        }
        
        evolution_phases = {
            'phase_1_initial': [],      # Syst√®mes initiaux TensorFlow
            'phase_2_improvement': [],   # Am√©liorations et optimisations
            'phase_3_advanced': [],      # Techniques avanc√©es
            'phase_4_validation': [],    # Validation et tests
            'phase_5_final': []          # Syst√®mes finaux
        }
        
        for system in systems_data:
            if not system:
                continue
                
            # Cat√©gorisation par technologie
            technologies = system.get('technologies', [])
            
            if 'TensorFlow' in technologies:
                categories['tensorflow_based'].append(system)
            if any(tech in technologies for tech in ['Scikit-Learn', 'Random Forest', 'Gradient Boosting']):
                categories['sklearn_based'].append(system)
            if 'Optuna' in technologies:
                categories['optimization_focused'].append(system)
            if 'Ensemble' in technologies:
                categories['ensemble_methods'].append(system)
            if any(tech in technologies for tech in ['Quantum', 'Genetic/Evolution']):
                categories['advanced_ai'].append(system)
            if system['system_type'] == 'Validator':
                categories['validation_systems'].append(system)
            if system['system_type'] == 'Analyzer':
                categories['analysis_tools'].append(system)
            
            # Cat√©gorisation par phase d'√©volution (bas√©e sur le nom et la date)
            file_name = system['file_name'].lower()
            creation_time = system['creation_time']
            
            if any(keyword in file_name for keyword in ['euromillions_model', 'create_', 'basic']):
                evolution_phases['phase_1_initial'].append(system)
            elif any(keyword in file_name for keyword in ['optimized', 'improved', 'enhanced']):
                evolution_phases['phase_2_improvement'].append(system)
            elif any(keyword in file_name for keyword in ['advanced', 'ultra', 'revolutionary', 'quantum']):
                evolution_phases['phase_3_advanced'].append(system)
            elif any(keyword in file_name for keyword in ['validator', 'validation', 'test']):
                evolution_phases['phase_4_validation'].append(system)
            elif any(keyword in file_name for keyword in ['final', 'ultimate', 'targeted']):
                evolution_phases['phase_5_final'].append(system)
        
        return categories, evolution_phases
        
    def extract_performance_data(self, systems_data):
        """Extrait les donn√©es de performance de tous les syst√®mes."""
        print("üìà Extraction des donn√©es de performance...")
        
        performance_summary = {}
        
        # Recherche dans les fichiers de r√©sultats
        result_files = glob.glob('/home/ubuntu/results/**/*.json', recursive=True)
        result_files.extend(glob.glob('/home/ubuntu/results/**/*.txt', recursive=True))
        
        for file_path in result_files:
            try:
                if file_path.endswith('.json'):
                    with open(file_path, 'r') as f:
                        data = json.load(f)
                    
                    # Extraction des m√©triques de performance
                    if isinstance(data, dict):
                        system_name = os.path.basename(file_path).replace('.json', '')
                        
                        metrics = {}
                        
                        # Recherche de m√©triques communes
                        if 'confidence_score' in data:
                            metrics['confidence'] = data['confidence_score']
                        if 'validation' in data and isinstance(data['validation'], dict):
                            validation = data['validation']
                            if 'total_matches' in validation:
                                metrics['total_matches'] = validation['total_matches']
                            if 'accuracy_percentage' in validation:
                                metrics['accuracy'] = validation['accuracy_percentage']
                        if 'performance' in data:
                            metrics.update(data['performance'])
                        
                        if metrics:
                            performance_summary[system_name] = metrics
                            
                elif file_path.endswith('.txt'):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Extraction de m√©triques depuis le texte
                    system_name = os.path.basename(file_path).replace('.txt', '')
                    
                    # Patterns de recherche
                    patterns = {
                        'correspondances': r'correspondances?[:\s]*([0-9]+)/([0-9]+)',
                        'confiance': r'confiance[:\s]*([0-9.]+)',
                        'score': r'score[:\s]*([0-9.]+)',
                        'accuracy': r'accuracy[:\s]*([0-9.]+)%?',
                        'precision': r'pr√©cision[:\s]*([0-9.]+)%?'
                    }
                    
                    metrics = {}
                    for metric_name, pattern in patterns.items():
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        if matches:
                            if metric_name == 'correspondances':
                                # Format sp√©cial pour correspondances
                                for match in matches:
                                    if len(match) == 2:
                                        metrics['matches'] = f"{match[0]}/{match[1]}"
                                        metrics['accuracy'] = (int(match[0]) / int(match[1])) * 100
                            else:
                                metrics[metric_name] = float(matches[0])
                    
                    if metrics:
                        performance_summary[system_name] = metrics
                        
            except Exception as e:
                continue
        
        return performance_summary
        
    def create_evolution_timeline(self, systems_data):
        """Cr√©e une timeline de l'√©volution des syst√®mes."""
        print("üìÖ Cr√©ation de la timeline d'√©volution...")
        
        # Tri par date de cr√©ation
        sorted_systems = sorted(systems_data, key=lambda x: x['creation_time'] if x else 0)
        
        timeline = []
        
        for i, system in enumerate(sorted_systems):
            if not system:
                continue
                
            timeline_entry = {
                'order': i + 1,
                'file_name': system['file_name'],
                'creation_date': datetime.fromtimestamp(system['creation_time']).strftime('%Y-%m-%d %H:%M'),
                'system_type': system['system_type'],
                'technologies': system['technologies'],
                'description_preview': system['description'][:100] + "..." if len(system['description']) > 100 else system['description'],
                'file_size_kb': round(system['file_size'] / 1024, 1)
            }
            
            timeline.append(timeline_entry)
        
        return timeline
        
    def analyze_technology_evolution(self, categories):
        """Analyse l'√©volution des technologies utilis√©es."""
        print("üî¨ Analyse de l'√©volution technologique...")
        
        tech_evolution = {
            'tensorflow_usage': len(categories['tensorflow_based']),
            'sklearn_usage': len(categories['sklearn_based']),
            'optimization_adoption': len(categories['optimization_focused']),
            'ensemble_methods': len(categories['ensemble_methods']),
            'advanced_ai_exploration': len(categories['advanced_ai']),
            'validation_emphasis': len(categories['validation_systems'])
        }
        
        # Analyse des tendances
        trends = {}
        
        # Tendance vers l'optimisation
        if tech_evolution['optimization_adoption'] > 0:
            trends['optimization_trend'] = "Forte adoption des techniques d'optimisation (Optuna)"
        
        # Tendance vers la validation
        if tech_evolution['validation_emphasis'] > 2:
            trends['validation_trend'] = "Emphasis croissante sur la validation scientifique"
        
        # Diversification technologique
        tech_count = sum(1 for count in tech_evolution.values() if count > 0)
        if tech_count >= 4:
            trends['diversification'] = "Forte diversification technologique"
        
        return tech_evolution, trends
        
    def generate_systems_inventory(self, systems_data, categories, evolution_phases, performance_data):
        """G√©n√®re un inventaire complet des syst√®mes."""
        print("üìã G√©n√©ration de l'inventaire complet...")
        
        inventory = {
            'analysis_date': datetime.now().isoformat(),
            'total_systems': len([s for s in systems_data if s]),
            'systems_by_category': {cat: len(systems) for cat, systems in categories.items()},
            'systems_by_phase': {phase: len(systems) for phase, systems in evolution_phases.items()},
            'performance_summary': performance_data,
            'detailed_systems': []
        }
        
        # Ajout des d√©tails de chaque syst√®me
        for system in systems_data:
            if not system:
                continue
                
            system_detail = {
                'name': system['file_name'],
                'type': system['system_type'],
                'technologies': system['technologies'],
                'description': system['description'],
                'file_size_kb': round(system['file_size'] / 1024, 1),
                'creation_date': datetime.fromtimestamp(system['creation_time']).strftime('%Y-%m-%d %H:%M'),
                'performance_indicators': system.get('performance_indicators', {}),
                'predictions_found': system.get('predictions_found', {})
            }
            
            inventory['detailed_systems'].append(system_detail)
        
        return inventory
        
    def save_analysis_results(self, inventory, timeline, tech_evolution, trends):
        """Sauvegarde tous les r√©sultats d'analyse."""
        print("üíæ Sauvegarde des r√©sultats d'analyse...")
        
        # Inventaire complet
        with open(f'{self.analysis_dir}/systems_inventory/complete_inventory.json', 'w') as f:
            json.dump(inventory, f, indent=2, default=str)
        
        # Timeline d'√©volution
        with open(f'{self.analysis_dir}/evolution_analysis/evolution_timeline.json', 'w') as f:
            json.dump(timeline, f, indent=2, default=str)
        
        # √âvolution technologique
        tech_analysis = {
            'technology_usage': tech_evolution,
            'trends_identified': trends,
            'analysis_date': datetime.now().isoformat()
        }
        
        with open(f'{self.analysis_dir}/evolution_analysis/technology_evolution.json', 'w') as f:
            json.dump(tech_analysis, f, indent=2, default=str)
        
        # Rapport de synth√®se
        synthesis_report = f"""
# ANALYSE R√âTROSPECTIVE COMPL√àTE - TOUS LES SYST√àMES D√âVELOPP√âS

## R√âSUM√â EX√âCUTIF
Date d'analyse: {datetime.now().strftime('%d/%m/%Y %H:%M')}
Nombre total de syst√®mes: {inventory['total_systems']}

## R√âPARTITION PAR CAT√âGORIE
{chr(10).join([f"- {cat.replace('_', ' ').title()}: {count} syst√®mes" for cat, count in inventory['systems_by_category'].items()])}

## √âVOLUTION TECHNOLOGIQUE
{chr(10).join([f"- {tech.replace('_', ' ').title()}: {count} syst√®mes" for tech, count in tech_evolution.items()])}

## TENDANCES IDENTIFI√âES
{chr(10).join([f"- {trend}: {description}" for trend, description in trends.items()])}

## TIMELINE D'√âVOLUTION
{chr(10).join([f"{entry['order']}. {entry['file_name']} ({entry['creation_date']}) - {entry['system_type']}" for entry in timeline[:10]])}

## SYST√àMES LES PLUS R√âCENTS
{chr(10).join([f"- {entry['file_name']} ({entry['creation_date']})" for entry in timeline[-5:]])}

## PERFORMANCE GLOBALE
Syst√®mes avec m√©triques de performance: {len(inventory['performance_summary'])}
{chr(10).join([f"- {name}: {metrics}" for name, metrics in list(inventory['performance_summary'].items())[:5]])}

---
Analyse g√©n√©r√©e automatiquement par l'Analyseur R√©trospectif Complet
"""
        
        with open(f'{self.analysis_dir}/synthesis_report.txt', 'w') as f:
            f.write(synthesis_report)
        
        print("‚úÖ Tous les r√©sultats sauvegard√©s!")
        
    def run_comprehensive_analysis(self):
        """Ex√©cute l'analyse compl√®te de tous les syst√®mes."""
        print("üöÄ LANCEMENT DE L'ANALYSE R√âTROSPECTIVE COMPL√àTE üöÄ")
        print("=" * 70)
        
        # 1. Scan de tous les syst√®mes
        print("üîç Phase 1: Scan de tous les syst√®mes...")
        system_files = self.scan_all_systems()
        
        # 2. Analyse d√©taill√©e de chaque syst√®me
        print("üìä Phase 2: Analyse d√©taill√©e...")
        systems_data = []
        for file_path in system_files:
            system_info = self.analyze_system_file(file_path)
            systems_data.append(system_info)
        
        # 3. Cat√©gorisation
        print("üìã Phase 3: Cat√©gorisation...")
        categories, evolution_phases = self.categorize_systems(systems_data)
        
        # 4. Extraction des performances
        print("üìà Phase 4: Extraction des performances...")
        performance_data = self.extract_performance_data(systems_data)
        
        # 5. Timeline d'√©volution
        print("üìÖ Phase 5: Timeline d'√©volution...")
        timeline = self.create_evolution_timeline(systems_data)
        
        # 6. Analyse technologique
        print("üî¨ Phase 6: Analyse technologique...")
        tech_evolution, trends = self.analyze_technology_evolution(categories)
        
        # 7. G√©n√©ration de l'inventaire
        print("üìã Phase 7: G√©n√©ration de l'inventaire...")
        inventory = self.generate_systems_inventory(systems_data, categories, evolution_phases, performance_data)
        
        # 8. Sauvegarde
        print("üíæ Phase 8: Sauvegarde...")
        self.save_analysis_results(inventory, timeline, tech_evolution, trends)
        
        print("‚úÖ ANALYSE R√âTROSPECTIVE COMPL√àTE TERMIN√âE!")
        
        return {
            'inventory': inventory,
            'timeline': timeline,
            'tech_evolution': tech_evolution,
            'trends': trends,
            'categories': categories,
            'evolution_phases': evolution_phases
        }

if __name__ == "__main__":
    # Lancement de l'analyse r√©trospective compl√®te
    analyzer = ComprehensiveSystemAnalyzer()
    results = analyzer.run_comprehensive_analysis()
    
    print(f"\nüîç R√âSULTATS DE L'ANALYSE R√âTROSPECTIVE:")
    print(f"Syst√®mes analys√©s: {results['inventory']['total_systems']}")
    print(f"Cat√©gories identifi√©es: {len(results['categories'])}")
    print(f"Phases d'√©volution: {len(results['evolution_phases'])}")
    print(f"Tendances technologiques: {len(results['trends'])}")
    
    print("\nüéâ ANALYSE R√âTROSPECTIVE TERMIN√âE! üéâ")

